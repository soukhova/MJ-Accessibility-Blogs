---
title: "Planning with accessibility measures: impedance functions"
format: 
  docx: default
  html: default
editor: source
author:
  - name: Anastasia Soukhov
    email: soukhoa@mcmaster.ca
    affiliation: School of Earth, Environment and Society, McMaster University, Hamilton, ON, L8S 4K1, Canada
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r library-setup}
library(TTS2016R) # An augmented 2016 Transportation Tomorrow Survey (TTS) data package: worker and place of employment counts, trips and estimated travel time to work in the Greater Golden Horsehoe area, Canada
library(sf) # Simple Features for R
library(ggplot2) # Create Elegant Data Visualisations Using the Grammar of Graphics
# library(tmap)
library(dplyr)# A Grammar of Data Manipulation 
```

```{r import-data}
ggh_pd <- TTS2016R::ggh_pd
ggh_pd <- st_buffer(ggh_pd, dist=0)
ggh_taz <- TTS2016R::ggh_taz
ggh_taz <- st_buffer(ggh_taz, dist=0)
ggh_taz <-  st_join(ggh_taz, ggh_pd |> transmute(PD),left = TRUE, largest = TRUE) #adding PD, we want to only visualize Hamilton PD 1

# drop travel times that have destinations
od  <- TTS2016R::od |> filter( !is.na(travel_time)) |> 
  mutate(travel_time = as.integer(ifelse(Destination == 9998 | Destination == 8888 | Origin == 9998 | Origin == 8888 
                                         | Destination >= 9000 | Origin >= 9000, NA, travel_time)))
od <- od |> 
  na.omit() #omitting rows with NA travel times - these are trips that happen to outside and/or unknown destinations. 
```

```{r intra-zonal-travel-time-est-1, include=FALSE}
# Imputing intra-zonal travel time. The proposed procedure is as follows:
# 1. Calculate the inter-zonal distances using the zone centroids as reference
# 2. Calculate the square root of the area of the zones; this is a proxy for the typical distance within the zone
# 3. Model the inter-zonal travel times as a function of inter-zonal distances; This gives a relationship distance-to-time t = f(d)
# 4. Use the model to estimate (i.e., impute) the travel time

# Retrieve the centroids of the TAZ
taz_centroids <- ggh_taz |>
  st_centroid()

# Calculate the inter-centroid distances
taz_dist <- st_distance(taz_centroids,
                        taz_centroids) |>
  matrix(ncol = 1, byrow = FALSE)

# Create a data frame with the origin destination ids and the distances
taz_dist <- cbind(expand.grid(Destination = taz_centroids$GTA06, 
                              Origin = taz_centroids$GTA06),
                  taz_dist) |>
  select(Origin, Destination, taz_dist)

# Sanity check: make sure that the distances were assigned correctly to origin-destination pairs
st_distance(taz_centroids |> filter(GTA06 == "1"), 
            taz_centroids |> filter(GTA06 == "100"))

# Join the intra-zonal distances to the od table
od <- od |>
  left_join(taz_dist,
            by = c("Origin", "Destination"))

# Sanity check: make sure that the distances were assigned correctly to origin-destination pairs
st_distance(taz_centroids |> filter(GTA06 == "1"), 
            taz_centroids |> filter(GTA06 == "21"))
```

```{r intra-zonal-travel-time-est-2}
# Join area of zone
od <- od |> 
  left_join(ggh_taz |> 
              st_drop_geometry() |> 
              transmute(GTA06,
                        PD, 
                        AREA), 
            by = c("Origin" = "GTA06"))

# Calculate the square root of the area of all zones; this is a proxy of the intra-zonal distance; note that the area is in sq.km so convert to meters. The inter-zonal distances are in m.
od <- od |>
  mutate(sqrt_area = ifelse(Origin == Destination, sqrt(AREA * 1000000), NA))

# Check the summary statistics of the sqrt of AREA to find the maximum distance that we wish to model
# summary(od$sqrt_area)
```

```{r intra-zonal-travel-time-est-3, include=FALSE}
# Estimate a model to correlate distance to travel time
zonal_time_mod <- lm(travel_time ~ taz_dist,   
                     data = od |>
                       filter(Origin != Destination,
                              taz_dist < 24000))

ggplot(data = od |>
         filter(Origin != Destination,
                taz_dist < 24000),
       aes(x = taz_dist,
           y = travel_time)) +
  geom_point(alpha = 0.2) +
  geom_abline(intercept = zonal_time_mod$coefficients[1], 
              slope = zonal_time_mod$coefficients[2],
              color = "red")
```

```{r intra-zonal-travel-time-est-4}
# Impute intrazonal travel times
od <- od |>
  mutate(travel_time = ifelse(Origin == Destination, 
                              # If intra-zonal (i.e., origin == destination) use model to impute travel time
                              zonal_time_mod$coefficients[1] + zonal_time_mod$coefficients[2] * sqrt_area,
                              # Else use the travel time already in the table
                              travel_time))
```

```{r select-hamilton-origins}
#keeping only trips originating from Hamilton IDs (the planning district of Hamilton)
ham_o_ids <- ggh_taz |> filter(PD == 46) |> data.frame() |> transmute(GTA06, AREA) #list of hamilton IDs

od_HAM_origin <- od |> filter(Origin %in% ham_o_ids$GTA06) #only keeping od trips that originate within Hamilton
```

```{r exploring-traveltimes-hamilton, include=FALSE}
#this is just to explore how the area relates to travel time... better than just assigning all to the 25th quantile I guess!.
ggplot(od_HAM_origin |> filter(travel_time <= 20), aes(x=travel_time, y=AREA)) + geom_point()
```

*Accessibility* (or *access*) has many definitions. Within the context of transportation planning, accessibility can be defined as a measure of the amount of interaction a population potentially has with opportunities in a given region. It is a product of the land-use and the population's means of transportation: the population are the people that live within the region and the opportunities are the destinations of interest to the population or of the transportation network itself. 

The population can be the total population or any subset in the region and the opportunities that can be modeled are limitless, for instance, they can be food markets, healthcare services, schools, places of employment, or even other populations. The output from accessibility measures are typically a value or normalized score that is assigned to each spatial unit (e.g., a census tract, neighbourhood, parcel, etc.) within the region. This score can help an analyst identify areas of spatial disparities in access for the region. Clarifying reviews of how accessibility measures have been used in the literature has been detailed, to name a few, in the unifying works of [@geurs2004] and [@wuUnifyingAccess2020] and an interesting discussion is provided by [@handy2020].

Due to of the adaptability of accessibility measure methods, they have been used in wide variety of transportation research and planning work throughout the years. What makes them popular is how they can be used to intuitively define and describe transportation and land-use disparities in opportunity access. Through the identification of disparities, associated interventions can be better informed: this is an important component in planning for equitable transportation service provision.

This blog post is the first part of a multi-part series. This series aims to walk readers through the potential uses of accessibility measures in transportation equity planning. This post explores how we can choose to assume travel behaviour in accessibility measures. In subsequent posts, how impedance functions impact accessibility measures, types of accessibility methods and methods to analysis equity are discussed.

## Counting opportunities through decaying distance

Many accessibility measures derive from one proposed first proposed by [@hansen1959] from definitions of demographic potential interaction defined by [@stewartDemographicGravitationEvidence1948]. This accessibility measure $A_i$ is represented in (@eq-hansen-access).

$$
A_i = \sum_{j=1}^JO_j \cdot f(c_{ij})
$$ {#eq-hansen-access}

Where: the accessibility score $A_i$ is a value calculated for each spatial unit $i$ through the summation of the number of opportunities $O$ at $j$ multiplied by the distance-decay function $f(c_{ij})$. $f(c_{ij})$ is some function that reflects how travel cost $c_{ij$ changes as distance between origin $i$ and destination $j$ changes. Recall, $i$ denotes each origin spatial unit in the region (e.g., $i$ represents one given census tract in the census tracts within the region). $j$ represents the destination spatial unit in the region.

The distance decay function $f(c_{ij})$ meters how much _"potential interaction"_ a population at $i$ can have with opportunities at all $j$s. It can be considered a generalized travel cost $c_{ij$ - be it distance, cost, or travel time. For this reason, distance-decay functions are often called _impedance_ functions as they model the impedance of travel. Generally speaking, opportunities at $j$ that are closer to a population at $i$ are more likely to be interacted with than the same opportunities for population at a further $i$. As such, $f(c_{ij})$ values for trips from $i$ to those $j$s are larger, so a larger values of the $O_j$ enter the summation. Conversely, it is highly unlikely that the population at $i$ will interact with certain opportunities at $j$ that are some *far* travel cost away. For those far trips, $f(c_{ij})$ is a value close to or equal to zero, so a negligible amount of $O_j$ enter the summation.

In short: the impedance function $f(c_{ij})$ allows the accessibility analyst to define how travel impedance defines the relationship between where people are (population) and where they go/want to go (opportunities).

From this perspective, the definition of the impedance function $f(c_{ij})$ is incredibly important. Let's go over commonly defined impedance functions in accessibility research and their impact on opportunity-counting at specific travel costs.

The first is shown in (@eq-binary-access), and is the foundation of the cumulative opportunity accessibility measure approach (this measure is discussed in the next post **LINK TO POST2**). The impedance function $f(c_{ij})$ is binary, where the function is either _some value_ or _some other value_. For simplicity, 1 or 0 are often used. 1 is assigned if the travel cost from $i$ to $j$ is below the threshold $T$. Conversely, it is 0 if the travel cost is above a certain threshold $T$. Threshold $T$ should be selected carefully to best fit the modelled population-to-opportunity context.

$$
f(c_{ij})^* =
\begin{cases}
 \text{1}\, & \text{if }c_{ij}\leq\text{T}\\
 \text{0}  & \text{otherwise}
 \end{cases}       
$$ {#eq-binary-access}

Next, three more complex impedance $f(c_{ij})$ functions are shown: these functions are [_probability density functions_](https://en.wikipedia.org/wiki/Probability_density_function) (PDF). In conceptualizing $f(c_{ij})$ as forms of PDF, the $f(c_ij)$ values (the probability density value along the y-axis) can be interpreted as the _relative liklihood_ of a trip occurring for each value of $c_ij$. The probability of a trip between a certain range of $c_ij$ is the area under the curve (the area under a PDF always equals to 1, i.e., 100% probability that the trip between the minimum and maximum $c_ij$ will occur). Let's go over three examples of commonly used theoretical PDFs in accessibility impedance functions.

The first can be seen as a binary function (like shown in (@eq-binary-access)) as it can only equal one of two values. However, whatever two values are selected must ensure that the area under the curve for the range of $c_ij$ is kept at 1. In this way, the binary function is equal to the theoretical _uniform density function_ shown in (@eq-uniform-imped). The parameters which the analyst chooses are $T_{max}$ and $T_{min}$: they equal the maximum and minimum travel cost (i.e., the range) it is assumed that a trip occurs. Outside of this range, the trip does not occur (the relative liklihood is assigned a zero). 

$$
f(c_{ij})^* =
\begin{cases}
 \frac{1}{T_{max}-T_{min}}\ & \text{for }T_{min} \leq\ c_{ij}\leq T_{max}\\
 \ 0  & \text{for } c_{ij} < T_{min} \text{ or } c_{ij} > T_{max}
 \end{cases}       
$${#eq-uniform-imped}

The next two functions are the exponential density function and the gamma density function (part of the exponential function facilities but utilizes the gamma function $\Gamma(\alpha)$). The general form of these two functions are shown in the following (@eq-exp-imped) and (@eq-gamma-imped). The analyst selects parameters for these functions represented by $\lambda$ (exponential) and $\alpha$ and $\sigma$ (gamma). Unlike the binary function (@eq-binary-access), these two functions can take a value of _relative liklihood_ from 0 to approaching infinity for all positive $c_{ij}$, where the range depends on the analyst-defined parameters.

$$
f(c_{ij}, \beta)^{**} = 
\begin{cases}
\lambda e^{-\lambda\cdot c_{ij}} & \text{for }c_{ij} \geq 0\\
 \ 0  & \text{for } c_{ij} < 0
 \end{cases}        
$${#eq-exp-imped}

$$
f(c_{ij})^{***} = 
\begin{cases}
\frac{1}{\sigma^\alpha\Gamma(\alpha)} c_{ij}^{\alpha-1} \cdot e^{{-c_{ij}}/{\sigma}} & \text{for } 0 \leq c_{ij} < \infty  ; \alpha, \sigma > 0\\
 \ 0  & \text{otherwise }
 \end{cases}   
$${#eq-gamma-imped}

In all three PDF, the analyst must define the parameters. A useful technique that can be used by analyst is to calibrate the parameters using empirically observed origin-to-destination (OD) travel data. This empirical data can be used to build a trip length distribution (TLD) and then best-fit parameters for the selected theoretical PDF can be identified. 

I will demonstrate this process as follows on a sample of empirical home-to-work flows from Hamilton Center from the R data package {TTS2016R} [@TTS2016r]. The flows are taken at the spatial unit of traffic analysis zones (TAZ). This package contains a subset of home-to-work flows the 2016 Transportation Tomorrow Survey (TTS) as well as calculated road-network car travel times (calculated using {r5r} [@r5r_2021]). {TTS2016R} is detailed in this publication [@soukhovTTS2016RDataSet2023] and is freely available [here](https://soukhova.github.io/TTS2016R/). The TLD for this empirical data is shown in black in the plot below:

```{r creating-TLD}
#creating 1 row for each OD trip (i.e., Persons = frequency)
all_tt <- od_HAM_origin  |> dplyr::select(Persons, travel_time)
all_tt <- all_tt[rep(seq_len(dim(all_tt)[1]), all_tt$Persons), 2]
# # all_tt_binned <- cut(all_tt, breaks = seq(0, 90, 5), include.lowest=TRUE, labels = c(5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90)) 
# all_tt_binned <- cut_width(all_tt, 5, boundary = 0) |> as.numeric() #cuts data into 0-5, 5-10, 10-20.... 85-90 bins, and then they are relabelled from 1 to 18 (18 us the 85-90 bin)

# all_tt_trans <- scales::rescale(all_tt, to = c(0.0,1)) #scaling values, from 0 to 1 range. 
# all_tt_trans_binned <- scales::rescale(all_tt_binned, to = c(0.0,1)) #scaling values, from 0 to 1 range. 

# fitdistrplus::descdist(data=all_tt)
# fitdistrplus::descdist(data=all_tt_trans)
# fitdistrplus::descdist(data=all_tt_binned)
# summary(all_tt)
```

```{r plotting-just-TLD}
#| label: fig-TLD-empirical
#| fig-cap: "Trip length distribution of home-to-work trips (in estimated minutes by car) for Hamilton Center."

empirical <-  density(all_tt)
empirical_x <- empirical$x
empirical_y <- empirical$y #|> scales::rescale()
empirical <- data.frame(f = empirical_y,
                        x = empirical_x,
                        type = "Empirical")

ggplot(data = empirical) + geom_line(aes(x=x, y=f), color="grey30") + 
  scale_x_continuous(expand = c(0, 0), limits = c(0, 88)) +
  theme_classic() +
  theme(legend.position  = "none") +
  xlab(bquote(c[ij])) +
  ylab(bquote(f(c[ij])))

#trips less than 40 mins in length
red_empirical <- empirical |> filter (x <= 45)
```

The TLD is the _empirical_ PDF of the travel costs associated with the OD trips. Like all PDFs, the y axis represents the relative liklihood of the value at the x axis of occurring. In our context, $f(c_{ij})$ is the relative liklihood of a OD trip of a given travel time (in minutes, $c_{ij}$) of occurring. It can be observed that a `r empirical |> filter(f == max(f)) |> pull(x) |> prettyNum(digits=2)` minute trip is the most likely (`r max(empirical$f) |> scales::percent()` relative liklihood in occurring). It can also be seen that around the 45 min mark, the relative liklihood levels off. In other words, the probability of a trip of length 0 to 45 mins occurring is  `r sum(diff(sort(red_empirical$x)) * 0.5 * (red_empirical$f[-1] + head(red_empirical$f, -1))) |> scales::percent()`. Trips outside of this range thus make up the remaining probability. 

Now let's fit the parameters of the uniform, exponential, and gamma functions (@eq-uniform-imped, @eq-exp-imped, @eq-gamma-imped) as closely to the TLD captured in @fig-TLD-empirical above. The R package {fitdistrplus} is used to generate parameters that best-fit the TLD: the moments matching estimation (MME) fitting-method and the Nelder-Mead direct optimization algorithms are used [@Muller2016]. The default values for all three functions are summarized as follows:

```{r testing-different-impedance-models, echo=FALSE, warning=FALSE, message=FALSE}
unif_ <- fitdistrplus::fitdist(data=all_tt, "unif", method="mme", optim.method="Nelder-Mead")
# unif_

# beta_ <- fitdistrplus::fitdist(data=all_tt_trans, "beta", method="mme", optim.method="Nelder-Mead", start=list(shape1=0.5, shape2=3))
# beta_
# plot(beta_)

# I'm picking gamma because it's part of the exponential family. Beta seems to be a better fit but its a bit more complicated. Gamma is a better fit than the less-complicated exp dist. The empirical data is not confidently 'from' any theoretical distribution (according to Kolmogorov-Smirnov test), but certain distirbutions fit the data better than others. 
gamma_ <- fitdistrplus::fitdist(data=all_tt, "gamma", method="mme", optim.method="Nelder-Mead")
# gamma_
# plot(gamma_)


#and we pick exponential for simplicity. It also fits okay!
exp_ <- fitdistrplus::fitdist(data=all_tt, "exp", method="mme", optim.method="Nelder-Mead")
# exp_
# plot(exp_)

# lognorm_ <- fitdistrplus::fitdist(data=all_tt, "lnorm", method="mle", optim.method="Nelder-Mead")
# lognorm_
# plot(lognorm_)

# ks.test(all_tt_trans, "pbeta", 0.5346627, 1.5293404)
# ks.test(all_tt, "plnorm", 2.6319398, 0.7176736)
# ks.test(all_tt |> sample(100), "pgamma", shape = 1.60289258, rate = 0.08911374)

# #generate dataset of 100 values that follow a Poisson distribution with mean=5
# data <- rgamma(n=500000, shape = 1.60289258, rate = 0.08911374)
# #perform Kolmogorov-Smirnov test
# ks.test(data, "pgamma", shape = 1.60289258, rate = 0.08911374)
```

-   Binary function ($f(c_{ij})^*$ - red): $T_{min}$ and $T_{max}$ is 0 and `r unif_$estimate[2] |> prettyNum(digits=1)` mins, respectively.

-   Exponential function ($f(c_{ij})^{**}$ - green)\*: $\beta$ (rate) is `r exp_$estimate |> prettyNum(digits=1)`

-   Gamma function ($f(c_{ij})^{***}$ - blue)\*: $\alpha$ (shape) is `r gamma_$estimate[1] |> prettyNum(digits=1)` and $\beta$ (rate) is `r gamma_$estimate[2] |> prettyNum(digits=1)`

```{r plotting-impedance-functions}
#| label: fig-TLD-all
#| fig-cap: "Trip length distribution (empirical) with fitted theoretical functions of home-to-work trips (in estimated minutes by car) for Hamilton Center."

travel_costs <- unique(od$travel_time)

fit_binary <- data.frame(f = dunif(travel_costs, min=0, max=unif_$estimate[2]), #already scaled from 1 to 0
                         x = travel_costs,
                         type = "Uniform (Eq. 3)")
fit_dexp <- data.frame(f = dexp(travel_costs, rate = exp_$estimate), #|> scales::rescale(),
                       x = travel_costs,
                       type = "Exp (Eq. 4)")
fit_dgamma <- data.frame(f = dgamma(travel_costs, shape = gamma_$estimate[1], rate = gamma_$estimate[2]), #|> scales::rescale(),
                         x = travel_costs,
                         type = "Gamma (Eq. 5)")

empirical <-  density(all_tt)
empirical_x <- empirical$x
empirical_y <- empirical$y #|> scales::rescale()
empirical <- data.frame(f = empirical_y,
                        x = empirical_x,
                        type = "Empirical")

TLDs <- rbind(fit_binary, fit_dexp, fit_dgamma, empirical)

ggplot(data = TLDs) + geom_line(aes(x=x, y=f, color=type), size=0.6) + 
    scale_x_continuous(expand = c(0, 0), limits = c(0, 88)) +
  theme_classic() +
  scale_color_manual(name = "Functions",
                     values = c("Red", "grey30", "Green", "Blue")) +
  xlab(bquote(c[ij])) +
  ylab(bquote(f(c[ij])))
```

Functions in @fig-TLD-all can be interpreted in the following way: the higher the $f(c_{ij})$, the more opportunities are available at destination $j$ can be interacted with. Using {fitdistrplus}, the parameters in all theoretical functions were selected through an optimization algorithm that minimizes the differences between all possible parameter range(s) and the empirical function for each theoretical function.

The uniform impedance function (red), when implemented into an accessibility calculation, would assume that the population is indifferent to changes in travel cost. The population at an origin is assumed to either totally interact with an opportunity (if it's a trip between 0 to 45 minutes - the $T$ thresholds) or not interact at all. 

If the above exponential or gamma function was implemented in an accessibility calculation, then the analyst is assuming the population is much more sensitive to changes in travel cost. However, the exponential and gamma functions are quite a different shape so they depict a different response to the relative liklihood of traveling given a travel cost $c_{ij}$. 

The exponential function (green) is intuitive to understand: the shorter the travel cost $c_{ij}$, the higher the $f(c_{ij})$ value. However, when compared to the empirical TLD (black) curve, we can see that the observed travel behaviour does not closely match this curve. Trip lengths that are `r empirical |> filter(f == max(f)) |> pull(x) |> prettyNum(digits=2)` mins in length have the highest relative liklihood and trips that are longer and shorter than this length occur less often and are assigned decreasing $f(c_{ij})$ values. For these reasons, the gamma function (blue) provides a fit that is closest to the empirical curve at the cost of a more complex mathetmatical formulation (see @eq-gamma-imped).

The impedance function reflects significant assumptions about travel behaviour. The selection of the type of function and associated parameters reflects how much impedance the modelled population faces reaching opportunities and hence their potential interaction. How the impedance function is used to explain accessibility functions will be discussed in next post **LINK TO POST2**. Feel free to explore the parameters interactively for the uniform, exponential and gamma functions [here](https://soukhova.shinyapps.io/Impedance-explained-shiny-app/).

_The TLD used in this post is a subset of data from {TTS2016R}, the goodness-of-fit criteria and diagnostics from {fitdistrplus} are used for model parameter selection, plots are generated using {ggplot2}, and spatial objects are manipulated using {sf}, along with base {R} functions. All the code and text in this post (including the interactive plot) is available in this GitHub repository [here](https://github.com/soukhova/MJ-Accessibility-Blogs)._

## References
