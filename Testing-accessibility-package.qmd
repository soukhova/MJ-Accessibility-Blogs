---
title: "Testing-accessibility-package"
format: html
editor: source
---

In this file, we test the {accessibility} package implementation of gravity() and spatial_availability() against the calculations in Soukhov et. al (2023).

```{r}
# Package calls annotated with package {annotater}
library(dplyr) # A Grammar of Data Manipulation
library(glue) # Interpreted String Literals
library(ggplot2) # Create Elegant Data Visualisations Using the Grammar of Graphics
library(sf) # Simple Features for R
library(tmap) # Thematic Maps
library(accessibility) # Transport Accessibility Measures
```
```{r spatial-avail-function, echo=FALSE}
sp_avail_detailed <- function(x, o_id, d_id, pop, opp, r, f, alpha = 1){
  
  o_id <- rlang::enquo(o_id)
  d_id <- rlang::enquo(d_id)
  pop <- rlang::enquo(pop)
  opp <- rlang::enquo(opp)
  r <- rlang::enquo(r)
  f <- rlang::enquo(f)
  
  sum_pop <- x |>
    dplyr::distinct(!!o_id,
                    .keep_all = TRUE) |>
    dplyr::mutate(sum_pop = !!r*(!!pop)^alpha) |>
    dplyr::pull(sum_pop) |>
    sum()
  
  f_p <- dplyr::pull(x, !!r) * dplyr::pull(x, !!pop)^alpha / sum_pop
  
  # Check that the grouping here is done by the destination;
    sum_impedance <- x |>
    dplyr::group_by(!!d_id) |>
    dplyr::summarize(sum_impedance = sum(!!f))
  # Compare to lines 34-35 of function accessibility::spatial_availability() where the grouping is based on the origin:
  # data[, `:=`(impedance_bal_fac, opp_weight/sum(opp_weight)), 
  #      by = c("from_id", group_by)]
  #
  # AP: I think formula (8) and the expressions that follow in page 12 of Soukhov et al. (2023) mean that the sum is over the origins, but grouping by destinations.
  # AP: I don't necessarily think that grouping over the origins is wrong, I think it means something different...need to think more about this. The mathematical notation needs to be refined too to indicate the domain of the sums, which at the moment is somewhat ambiguous.
  
  x <- x |>
    dplyr::left_join(sum_impedance,
                     by = rlang::as_name(d_id))
  
  f_c <- dplyr::pull(x, !!f) / x$sum_impedance
  
  x$f_c <- f_c
  x$f_p <- f_p
  
  sum_pa <- x |>
    dplyr::group_by(!!d_id) |>
    dplyr::summarize(sum_pa= sum(f_p * f_c))
  
  x <- x |>
    dplyr::left_join(sum_pa,
                     by = rlang::as_name(d_id))
  x$f_t <- (f_p * f_c) / dplyr::pull(x, sum_pa)
  
  x |>
    dplyr::mutate(V_ij = !!opp * f_t)
}
```
```{r import-data}
ggh_pd <- TTS2016R::ggh_pd
ggh_pd <- st_buffer(ggh_pd, dist=0)
ggh_taz <- TTS2016R::ggh_taz
ggh_taz <- st_buffer(ggh_taz, dist=0)
ggh_taz <-  st_join(ggh_taz, ggh_pd |> transmute(PD),left = TRUE, largest = TRUE) #adding PD, we want to only visualize Hamilton PD 1

# drop travel times that have destinations
od  <- TTS2016R::od |> filter( !is.na(travel_time)) |> 
  mutate(travel_time = as.integer(ifelse(Destination == 9998 | Destination == 8888 | Origin == 9998 | Origin == 8888 
                                         | Destination >= 9000 | Origin >= 9000, NA, travel_time)))

od <- od |> 
  na.omit() #omitting rows with NA travel times - these are trips that happen to outside and/or unknown destinations. 
```
```{r intra-zonal-travel-time-est-1, include=FALSE}
# Imputing intra-zonal travel time. The proposed procedure is as follows:
# 1. Calculate the inter-zonal distances using the zone centroids as reference
# 2. Calculate the square root of the area of the zones; this is a proxy for the typical distance within the zone
# 3. Model the inter-zonal travel times as a function of inter-zonal distances; This gives a relationship distance-to-time t = f(d)
# 4. Use the model to estimate (i.e., impute) the travel time

# Retrieve the centroids of the TAZ
taz_centroids <- ggh_taz |>
  st_centroid()

# Calculate the inter-centroid distances
taz_dist <- st_distance(taz_centroids,
                        taz_centroids) |>
  matrix(ncol = 1, byrow = FALSE)

# Create a data frame with the origin destination ids and the distances
taz_dist <- cbind(expand.grid(Destination = taz_centroids$GTA06, 
                              Origin = taz_centroids$GTA06),
                  taz_dist) |>
  select(Origin, Destination, taz_dist)

# Sanity check: make sure that the distances were assigned correctly to origin-destination pairs
st_distance(taz_centroids |> filter(GTA06 == "1"), 
            taz_centroids |> filter(GTA06 == "100"))

# Join the intra-zonal distances to the od table
od <- od |>
  left_join(taz_dist,
            by = c("Origin", "Destination"))

# Sanity check: make sure that the distances were assigned correctly to origin-destination pairs
st_distance(taz_centroids |> filter(GTA06 == "1"), 
            taz_centroids |> filter(GTA06 == "21"))
```
```{r intra-zonal-travel-time-est-2, echo=FALSE}
# Join area of zone
od <- od |> 
  left_join(ggh_taz |> 
              st_drop_geometry() |> 
              transmute(GTA06,
                        PD, 
                        AREA), 
            by = c("Origin" = "GTA06"))

# Calculate the square root of the area of all zones; this is a proxy of the intra-zonal distance; note that the area is in sq.km so convert to meters. The inter-zonal distances are in m.
od <- od |>
  mutate(sqrt_area = ifelse(Origin == Destination, sqrt(AREA * 1000000), NA))

# Check the summary statistics of the sqrt of AREA to find the maximum distance that we wish to model
# summary(od$sqrt_area)
```
```{r intra-zonal-travel-time-est-3, include=FALSE}
# Estimate a model to correlate distance to travel time
zonal_time_mod <- lm(travel_time ~ taz_dist,   
                     data = od |>
                       filter(Origin != Destination,
                              taz_dist < 24000))

ggplot(data = od |>
         filter(Origin != Destination,
                taz_dist < 24000),
       aes(x = taz_dist,
           y = travel_time)) +
  geom_point(alpha = 0.2) +
  geom_abline(intercept = zonal_time_mod$coefficients[1], 
              slope = zonal_time_mod$coefficients[2],
              color = "red")
```
```{r intra-zonal-travel-time-est-4, include=FALSE}
# Impute intrazonal travel times
od <- od |>
  mutate(travel_time = ifelse(Origin == Destination, 
                              # If intra-zonal (i.e., origin == destination) use model to impute travel time
                              zonal_time_mod$coefficients[1] + zonal_time_mod$coefficients[2] * sqrt_area,
                              # Else use the travel time already in the table
                              travel_time))
```

```{r adding-workers-and-jobs-to-land-use, include=FALSE}
workers <- od |> 
  group_by(Origin) |> 
  summarize(workers = sum(Persons))

jobs <- od |> 
  group_by(Destination) |> 
  summarize(jobs = sum(Persons))

od <- merge(od, 
            workers, 
            by="Origin")
od <- merge(od, 
            jobs, 
            by="Destination")

#update the workers and jobs in the ggh_taz file.
ggh_taz <- ggh_taz |> 
  select(-c("workers", "jobs"))
ggh_taz <- ggh_taz |> 
  merge(workers, 
        by.x = "GTA06",
        by.y="Origin",
        all = T)
ggh_taz <- ggh_taz |> 
  merge(jobs, 
        by.x = "GTA06", 
        by.y = "Destination", 
        all=T)

ggh_taz$workers |> sum(na.rm=T)
ggh_taz$jobs |> sum(na.rm=T)

#make sure that the above two lines yield the same number.. this is the number of people who make trips from origin to jobs inthe GGH (3,052,233 people)
od$Persons |> sum() 
```

```{r preparing-impedance-values, echo=FALSE, warning=FALSE}
# calc impedance value using the same formulas used for the plot above.
od <- od |>
  mutate(f_bin = ifelse(travel_time > gamma_bin, 0, 1),
         f_exp = dexp(travel_time, rate = rate_exp),
         f_gamma = dgamma(travel_time, shape = shape_gamma, rate = rate_gamma),
         f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) #AS: we need to deal with zeros.. causes some NaN as a result of Inf values. For now, let's set 0s to be very small numbers.
```

```{r unconstrained-access-calculations, echo=FALSE, warning=FALSE}
# Accessibility - Level of service 
LOS_j <- od |>
  group_by(Destination) |>
  summarize(opp = first(jobs),
            R_j_bin = sum(workers * f_bin),
            R_j_exp = sum(workers * f_exp),
            R_j_gamma = sum(workers * f_gamma),
            .groups = "drop") |>
  mutate(R_j_bin = ifelse(R_j_bin == 0, NA, R_j_bin),
         #R_j_exp = ifelse(R_j_exp == 0,0.00000000000000000001, R_j_exp),
         #R_j_gamma = ifelse(R_j_gamma == 0,0.00000000000000000001, R_j_gamma),
         LOS_j_bin = opp/R_j_bin,
         LOS_j_exp = opp/R_j_exp,
         LOS_j_gamma = opp/R_j_gamma)

# Hansen- accessibility
S <- od |>
  left_join(LOS_j |> 
              dplyr::select(Destination),
            by = "Destination") |>
  group_by(Origin) |>
  summarize(S_i_bin= sum(jobs * f_bin, na.rm=T),
            S_i_exp= sum(jobs * f_exp, na.rm=T), 
            S_i_gamma = sum(jobs * f_gamma, na.rm=T))
```

```{r constrained-access-calculations, echo=FALSE, warning=FALSE}
# Spatial availability disaggregated - binary
V_ij_bin <- od |> 
  #mutate(f_bin = ifelse(f_bin == 0, 0.00000000000000000001, f_bin)) |>
  mutate(r = 1) |>
  sp_avail_detailed(o_id = Origin,
                    d_id = Destination, 
                    pop = workers, 
                    opp = jobs, 
                    r = r, 
                    f = f_bin, 
                    alpha = 1.0) #alpha 1.54 

V_i_bin <- V_ij_bin |>
  group_by(Origin) |>
  summarise(V_i_bin = sum(V_ij))

# Spatial availability disaggregated - exponential
V_ij_exp <- od |> #mutate(f_exp = ifelse(f_exp == 0, 0.00000000000000000001, f_exp)) |> 
  mutate(r = 1) |>
  sp_avail_detailed(o_id = Origin,
                    d_id = Destination, 
                    pop = workers, 
                    opp = jobs, 
                    r = r, 
                    f = f_exp, 
                    alpha = 1.0) #alpha 1.54 

V_i_exp <- V_ij_exp |>
  group_by(Origin) |>
  summarise(V_i_exp = sum(V_ij)) |> 
  select(-Origin)

# Spatial availability disaggregated - gamma
V_ij_gamma <- od |> #mutate(f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) |> 
  mutate(r = 1) |>
  sp_avail_detailed(o_id = Origin,
                    d_id = Destination, 
                    pop = workers, 
                    opp = jobs, 
                    r = r, 
                    f = f_gamma, 
                    alpha = 1.0) #alpha 1.54 

V_i_gamma <- V_ij_gamma |>
  group_by(Origin) |>
  summarise(V_i_gamma = sum(V_ij)) |>
  select(-Origin)

V <- cbind(V_i_bin, V_i_exp, V_i_gamma)

#checking to make sure they add up to the jobs in GGH -> 3,052,233 people go to jobs in GGH
V$V_i_bin |> sum(na.rm=T)
V$V_i_exp |> sum(na.rm=T)
V$V_i_gamma |> sum()

od$Persons |> sum() # there are 3,052,233 people make trips from origin to jobs in the GGH.
```

```{r extra-calc-shen-for-comparision}
# Shen-type accessibility and 'equivalent' balancing factor in Shen. Here we can see 'a' should be equal to v (spatial availability divided by worker)
a <- od |>
  left_join(LOS_j |> dplyr::select(Destination,
                                   LOS_j_bin, LOS_j_exp, LOS_j_gamma),
            by = "Destination") |>
  #mutate(f_bin = ifelse(f_bin == 0, 0.000001, f_bin)) |>
  group_by(Origin) |>
  summarize(a_i_bin = sum((LOS_j_bin * f_bin), 
                          na.rm=T),  #Shen/2SFCA,
            a_i_exp = sum((LOS_j_exp * f_exp), 
                          na.rm=T), 
            a_i_gamma = sum((LOS_j_gamma * f_gamma), 
                            na.rm=T),
            .groups = "drop")

a |> summary()
```

```{r join-results}
# Join all results to traffic analysis zones
ggh_taz_acc <- ggh_taz |> 
  dplyr::select(-c(AREA)) |>
  merge(S,
        by.x = c("GTA06"), by.y = c("Origin"), all=TRUE) |>
  merge(V,
        by.x = c("GTA06"), by.y = c("Origin"), all=TRUE) |>
  merge(a,
        by.x = c("GTA06"), by.y = c("Origin"), all=TRUE)

ggh_taz_acc <- ggh_taz_acc |> 
  mutate(workers = ifelse(is.na(workers), 0, workers),
         jobs = ifelse(is.na(jobs), 0, jobs))

ggh_taz_acc <- ggh_taz_acc |>
  mutate(#jobs = replace_na(jobs, 0),
    v_i_bin = V_i_bin/workers,
    v_i_exp = V_i_exp/workers,
    v_i_gamma = V_i_gamma/workers) # Shen=type accessibility in number of jobs after multiplying by opportunity-seeking population)
```

```{r verify-employment}
# Regional total number of jobs (this is the number of jobs in each TAZ in Toronto as defined by the TTS). Equals to the number of workers.
ggh_taz_acc |>
  st_drop_geometry() |>
  select(workers) |> sum(na.rm=T)
ggh_taz_acc$jobs |> sum(na.rm=T)

# Verify that v_i times workers adds up to regional total.. a_i has some missing values currently - will fix later. point is v_i is correct.
ggh_taz_acc |>
  st_drop_geometry() |>
  #transmute(jobs = A_i * workers) |>
  summarize(jobs = sum(v_i_bin*workers, 
                       na.rm = TRUE),
            jobs2 = sum(a_i_exp*workers,
                        na.rm=TRUE))

# Testing... Jobs2 (i.e., shen's jobs should when multipled by workers equal to v_i_bin. I know v_i_bin,exp,gamma is correct because V_i is correct. Interestingly, a_i_exp is correct! but not a_i_bin or a_i_gamma. They do not sum to 3,052,233). Let's do some exploration below... I can't figure it out still :/
test <- data.frame(ggh_taz_acc$GTA06, ggh_taz_acc$a_i_bin |> round(digits = 5), 
                   ggh_taz_acc$v_i_bin|> round(digits = 5), 
                   ggh_taz_acc$a_i_bin |> round(digits = 5)== ggh_taz_acc$v_i_bin|> round(digits = 5))

test1 <- od |>
  left_join(LOS_j |> dplyr::select(Destination,
                                   LOS_j_bin, LOS_j_exp, LOS_j_gamma),
            by = "Destination") |>
  filter(Origin == "1037") |>
  mutate(a_i_bin = sum(LOS_j_bin * f_bin, na.rm=T),  #Shen/2SFCA,
         a_i_exp = sum(LOS_j_exp * f_exp, na.rm=T), 
         a_i_gamma = sum(LOS_j_gamma * f_gamma, na.rm=T))
```

```{r verify-population}
# Regional total population
ggh_taz_acc |>
  st_drop_geometry() |>
  summarize(workers = sum(workers,
                          na.rm = TRUE))


# Regional total opportunity-seeking population in spatial availability
ggh_taz_acc |>
  st_drop_geometry() |>
  summarize(workers_bin = sum(V_i_bin,
                              na.rm = TRUE),
            workers_exp = sum(V_i_exp,
                              na.rm = TRUE),
            workers_gamma = sum(V_i_gamma,
                                na.rm = TRUE))
```

```{r testing-using-accessibilitypackage, echo=FALSE, warning=FALSE}
#Reformatting for input into the accessibility() function. I'm doing this to test the accessibility funcitno for how it calculates, bin, exp, and gamma hansen-type accessibility (S_i). 
#od_short <- od |> transmute(Origin, Destination, travel_time_coale) |>

# Retrieve jobs and workers from the same data table that was used to calculate accessibility above
taz_short_workers <- od |>
  transmute(id = Origin,
            workers) |>
  distinct(id, .keep_all = TRUE)

taz_short_jobs <- od |>
  transmute(id = Destination,
            jobs) |>
  distinct(id, .keep_all = TRUE)

taz_short_2 <- taz_short_workers |>
  full_join(taz_short_jobs,
            by = "id") |>
  drop_na()

# Previous version
od_short <- od |> 
  transmute(Origin, 
            Destination, 
            travel_time) |>
  rename("from_id" = Origin ,
         "to_id" = Destination,
         "tt" = travel_time)

taz_short <- ggh_taz |> 
  st_drop_geometry() |> 
  transmute(GTA06, 
            workers, 
            jobs) |>
  rename("id" = GTA06) |> 
  mutate(workers = ifelse(is.na(workers), 0, workers),
         jobs = ifelse(is.na(jobs), 0, jobs))

#impedance functions for the function's use
my_binary <- function(x) {
  weights <- ifelse(x > gamma_bin, 0, 1) 
  return(weights)
}

## AP: DO NOT RESCALE; I commented out `|> scales::rescale()`
my_exp <- function(x) {
  weights <- dexp(x, rate = rate_exp)#  |> scales::rescale()
  # The exponential function never gives zeros
  #weights <- ifelse(weights == 0, 0.00000000000000000001, weights)
  return(weights)
}
#my_exp(c(0.1,1,10,30,100,180,190,200)) #testing output from function... it's correct!

## AP: DO NOT RESCALE; I commented out `|> scales::rescale()`
my_gamma <- function(x) {
  weights <- dgamma(x, shape = shape_gamma, rate = rate_gamma)# |> scales::rescale()
  weights <- ifelse(weights == 0, 0.00000000000000000001, weights)
  return(weights)
}
# my_gamma(c(0,1,10,30,100)) #testing output from function... it's correct!

# calc for package... let's try unconstrained first
unconstrained_bin <- gravity(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  travel_cost = "tt",
  decay_function = my_binary) |> 
  rename("S_i_bin_pkg" = jobs)

# NOTE: using this function gives us the same results as the one above ^
# unconstrained_bin2 <- cumulative_cutoff(
#   travel_matrix = od_short,
#   land_use_data = taz_short,
#   opportunity = "jobs",
#   travel_cost = "travel_time",
#   cutoff = 20) |> rename("S_i_bin_pkg" = jobs)

unconstrained_exp <- gravity(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  travel_cost = "tt",
  decay_function = my_exp) |> 
  rename("S_i_exp_pkg" = jobs)

unconstrained_gamma <- gravity(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  travel_cost = "tt",
  decay_function = my_gamma)  |> rename("S_i_gamma_pkg" = jobs)

package_S <- merge(unconstrained_bin,unconstrained_exp, by="id", all=T) 
package_S <- merge(package_S, unconstrained_gamma, by="id", all=T)

# add to taz (... a test for now)
#test <- merge(ggh_taz_acc, package_S, by.x=("GTA06"), by.y=("id"), all=TRUE)

test <- merge(S, package_S, by.x=("Origin"), by.y=("id"), all=TRUE)

#so we have a problem... the binary produced using accessibility() is correct! but not exp or gamma. We'll get back to this later.. It isn't an issue with my function, I tried the default exponential function with my parameter and the function's results were the same as the ones below. Maybe I calculate accessibility wrong..? But why does the binary one work?
## AP: The results seem to match after removing the rescaling
test |> select(c(S_i_bin, S_i_bin_pkg, S_i_exp, S_i_exp_pkg, S_i_gamma, S_i_gamma_pkg)) |> head()
```

<!-- THE ISSUE IS CONTAINED NOW TO THIS SECTION HERE -->

<!-- Function accessibility::spatial_availability does the summation of the impedance over the origins, whereas in the paper it is done over the destinations. AP forked the package and changed the function. After this the results are identical. -->

```{r testing-using-accessibilitypackage-2, echo=FALSE, warning=FALSE}
# Let's test the spatial_availability function in the accessibility() package.

#just gamma for now... (I also tried bin and exp)
constrained_exp <- spatial_availability(travel_matrix = od_short,
                                        land_use_data = taz_short,
                                        opportunity = "jobs",
                                        demand = "workers",
                                        travel_cost = "tt",
                                        decay_function = my_exp,
                                        alpha = 1) |> 
  rename("V_i_exp_pkg" = jobs)

# add to taz (... a test for now)
#test <- merge(ggh_taz_acc, constrained_exp, by.x=("GTA06"), by.y=("id"), all=TRUE)
test <- merge(V, 
              constrained_exp, 
              by.x=("Origin"), 
              by.y=("id"), 
              all=TRUE)

#so we have a problem... the exp produced does not match the spatial_avail_detailed() output. This is troubling...
test |> select(c(V_i_exp, V_i_exp_pkg)) |> head()
```
<!-- END OF PROBLEMATIC CODE --> <!-- AFTER THIS THE RESULTS OF ANASTASIA'S CODE AND THE RESULTS OF PACKAGE {accessibility} MATCH -->

```{r testing-using-accessibilitypackage-3, echo=FALSE, warning=FALSE}
#Now let's test shen-type acessibiilty, 2sfca! 
constrained_bin_a <- floating_catchment_area(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  demand = "workers",
  travel_cost = "tt",
  decay_function = my_binary,
  method = "2sfca") |> rename("a_i_bin_pkg" = jobs)

constrained_exp_a <- floating_catchment_area(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  demand = "workers",
  travel_cost = "tt",
  decay_function = my_exp,
  method = "2sfca") |> rename("a_i_exp_pkg" = jobs)

constrained_gamma_a <- floating_catchment_area(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  demand = "workers",
  travel_cost = "tt",
  decay_function = my_gamma,
  method = "2sfca") |> rename("a_i_gamma_pkg" = jobs)

package_a <- merge(constrained_bin_a,constrained_exp_a, by="id", all=T) 
package_a <- merge(package_a, constrained_gamma_a, by="id", all=T)

# add to taz 
test <- merge(ggh_taz_acc, package_a, by.x=("GTA06"), by.y=("id"), all=TRUE)

#yay my calc of a_i matches the function! Great. 
test |> select(c(a_i_bin, a_i_bin_pkg, a_i_exp, a_i_exp_pkg, a_i_gamma, a_i_gamma_pkg)) |> head()
test1 <- test |> select(c(a_i_bin, a_i_bin_pkg, a_i_exp, a_i_exp_pkg, a_i_gamma, a_i_gamma_pkg)) 
```

```{r}
# AP: THE RESULTS NOW MATCH EXACTLY

# what is a really interesting finding though is... my calculation of 2sfca is slightly off it seems and the package calculates it correctly! My calculation is correct for exp only. Not sure why..
test |>
  st_drop_geometry() |>
  #transmute(jobs = A_i * workers) |>
  summarize(jobs_vi_exp = sum(v_i_exp*workers, 
                              na.rm = TRUE),
            jobs_ai_exp = sum(a_i_exp*workers,
                              na.rm=TRUE),
            jobs_ai_exp_pkg = sum(a_i_exp_pkg*workers,
                                  na.rm=TRUE),
            jobs_vi_gamma = sum(v_i_gamma*workers, 
                                na.rm = TRUE),
            jobs_ai_gamma = sum(a_i_gamma*workers,
                                na.rm=TRUE),
            jobs_ai_gamma_pkg = sum(a_i_gamma_pkg*workers,
                                    na.rm=TRUE))
```

```{r access-unconstrained-reformating-for-plotting}
# filter the taz so only hamilton center area. This is for plotting purposes
ham_taz<- ggh_taz_acc |> filter(PD == 46)

ham_taz <- ham_taz |> 
  mutate(S_i_bin_norm= S_i_bin / sum(S_i_bin, na.rm=T) *100,
         S_i_exp_norm= S_i_exp / sum(S_i_exp, na.rm=T)*100,
         S_i_gamma_norm = S_i_gamma / sum(S_i_gamma, na.rm=T)*100)

# add a cat. variable to each sf object and bind them with rbind. then make them into a faceted tmap. 
ham_taz_Sibin_norm <- ham_taz |>  
  mutate(type =  glue("Relative Si (binary)") ) |>
  select(S_i_bin_norm, S_i_bin, type) |> 
  rename(S_i_norm = S_i_bin_norm,
         S_i = S_i_bin)

ham_taz_Siexp_norm <- ham_taz|> 
  mutate(type =  glue("Relative Si (exponential)") ) |>
  select(S_i_exp_norm, S_i_exp, type) |> 
  rename(S_i_norm = S_i_exp_norm,
         S_i = S_i_exp)

ham_taz_Sigamma_norm<- ham_taz|>
  mutate(type =  glue("Relative Si (gamma)") ) |>
  select(S_i_gamma_norm, S_i_gamma, type) |> 
  rename(S_i_norm = S_i_gamma_norm,
         S_i = S_i_gamma)

ham_taz_Si_facet <- rbind(ham_taz_Sibin_norm, ham_taz_Siexp_norm, ham_taz_Sigamma_norm)
ham_taz_Si_facet |> summary()
```


Further, accessibility is calculated for the full GGH region but we only visualize the Hamilton Center region for the purpose of illustration. The *unconstrained* accessibility plots are plotted: from left to right, uniform, expoential, and gamma.

```{r access-unconstrained-plots}
# now plot w/ facet
uncon_plots <- tm_shape(ham_taz_Si_facet) +
  tm_polygons("S_i_norm",
              palette = c("red", "yellow", "darkgreen"),
              style ="cont",
              breaks=c(-0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, +2.2), 
              label = c(">0.4%", "0.6%", "0.8%","1.0%", "1.2%","1.4%", "1.6%", "1.8%", "2.0%","<2.2%"),
              title = glue_col("% of total potential job interactions in the region
              *{sum(ham_taz_Si_facet$`S_i`[which(ham_taz_Si_facet$type == 'Relative Si (binary)')], na.rm=T) |> round()} (Si binary), {sum(ham_taz_Si_facet$`S_i`[which(ham_taz_Si_facet$type == 'Relative Si (exponential)')], na.rm=T) |> round()} (Si exp), and {sum(ham_taz_Si_facet$`S_i`[which(ham_taz_Si_facet$type == 'Relative Si (gamma)')], na.rm=T) |> round()} (Si gamma)"),
              legend.is.portrait = FALSE)+
  tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
  tm_compass(position = c("left", "top"), size=1.0)+
  tm_facets("type", ncol = 3) +
  tm_layout(asp = 1.5,
            legend.outside=TRUE, 
            legend.outside.position = "bottom",
            legend.position = c(0.2, 0.25),
            legend.title.size = 0.9)

#% of total jobs in the region - {sum(S_i, na.rm=T) |> round()} jobs (Si binary), {sum(S_i_exp, na.rm=T) |> round()} jobs (Si exp), and {sum(S_i_gamma, na.rm=T) |> round()} jobs (Si gamma)
```

In the plots above, we visualize the three plots. Each displays the relative accessibility value as a percentage of the total opportunities in the region (61296 jobs, 48744 jobs and 66190 jobs for binary, expoential, and gamma functions respectively). This rescaling is done so values can be interpreted on the same scale.

Before rescaling, the raw values can be understood as the number of job opportunities within the GGH that I can potentially interact with given the impedance function. For instance, for neighbourhoods with "high" accessibility (Greens - 1.80% relative values or higher), according to the binary impedance this means they can interact with `r (1.8/100)*2970995 |> round(digits=-3)` jobs or more by a 20 min car travel time (our selected threshold). For the exponential and gamma functions this "high" relative value is equivalent to `r (1.8/100)*2093825|> round(digits=-3)` and `r (1.8/100)*3086152|> round(digits=-3)` or higher potential jobs interactions. These raw values are difficult to interpret, so seeing a neighbourhood as being an area of relative 'high', 'medium' or 'low' accessibility value is simplest.

<!-- You can see that the range of raw accessibility values differ depending on the impedance function used. This is because the functions weight the opportunities counted in the calculation in differing ways. A common accessibility maximum cannot be determined across all three impedance function since accessibility is a function of the summation of weighted opportunities. For this reason, rescaling the accessibility values, as done in the plots above, is often done to make sense of relative 'highs' and 'lows' in the region. -->

Interestingly though, the trends across all impedance functions visually look similar - red, yellow, and green areas similar across all plots with some variation in intensity.

Next, we visualize *constrained* accessibility (spatial availability $V_i$). Like the plots above, from left to right: uniform, expoential, and gamma.

```{r access-constrained-reformating-for-plotting}
ham_taz <- ham_taz |> 
  mutate(V_i_bin_norm= V_i_bin / sum(V_i_bin, na.rm=T) *100,
         V_i_exp_norm= V_i_exp / sum(V_i_exp, na.rm=T)*100,
         V_i_gamma_norm = V_i_gamma / sum(V_i_gamma, na.rm=T)*100)

# add a cat. variable to each sf object and bind them with rbind. then make them into a faceted tmap. 
ham_taz_Vibin_norm <- ham_taz |>  
  mutate(type =  glue("Relative Vi (binary)") ) |>
  select(V_i_bin_norm, V_i_bin, type) |> 
  rename(V_i_norm = V_i_bin_norm,
         V_i = V_i_bin)

ham_taz_Viexp_norm <- ham_taz|> 
  mutate(type =  glue("Relative Vi (exponential)") ) |>
  select(V_i_exp_norm, V_i_exp, type) |> 
  rename(V_i_norm = V_i_exp_norm,
         V_i = V_i_exp)

ham_taz_Vigamma_norm<- ham_taz|>
  mutate(type =  glue("Relative Vi (gamma)") ) |>
  select(V_i_gamma_norm, V_i_gamma, type) |> 
  rename(V_i_norm = V_i_gamma_norm,
         V_i = V_i_gamma)

ham_taz_Vi_facet <- rbind(ham_taz_Vibin_norm, ham_taz_Viexp_norm, ham_taz_Vigamma_norm)
ham_taz_Vi_facet |> summary()

# this is interesting, around ~85,000 jobs are allocated to the Hamilton Center region. Though 102,000 jobs are located in the center and 104,000 people live there. This indicates that people who live here may not work here (?). This needs to be thought through...
ham_taz$V_i_bin |> sum(na.rm=T)
ham_taz$V_i_exp |> sum(na.rm=T)
ham_taz$V_i_gamma |> sum(na.rm=T)
ham_taz$jobs |> sum(na.rm=T)
ham_taz$workers |> sum(na.rm=T)
```

```{r access-constrained-plots}
# # now plot w/ facet. NOTE: this is one for the unconverted Vi values.
# tm_shape(ham_taz_Vi_facet) +
#   tm_polygons("V_i",
#               palette = c("red", "yellow", "darkgreen"),
#               style ="cont",
#               breaks=c(-200, 400, 600, 800, 1000, 1200, +1400), 
#               label = c(">200", "400", "600","800", "1000","1200", "<1400"),
#               title = glue_col("spatially available job opportunities in the region"),
#               legend.is.portrait = FALSE)+
#   tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
#   tm_compass(position = c("left", "top"), size=1.0)+
#   tm_facets("type", ncol = 3) +
#   tm_layout(asp = 1.5,
#             legend.outside=TRUE, 
#             legend.outside.position = "bottom",
#             legend.position = c(0.2, 0.25),
#             legend.title.size = 0.9)

con_plots <- tm_shape(ham_taz_Vi_facet) +
  tm_polygons("V_i_norm",
              palette = c("red", "yellow", "darkgreen"),
              style ="cont",
              breaks=c(-0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, +2.2), 
              label = c(">0.4%", "0.6%", "0.8%","1.0%", "1.2%","1.4%", "1.6%", "1.8%", "2.0%","<2.2%"),
              title = glue_col("% of total potentially available job interactions in the region
              *{sum(ham_taz_Vi_facet$`V_i`[which(ham_taz_Vi_facet$type == 'Relative Vi (binary)')], na.rm=T) |> round()} (Vi binary), {sum(ham_taz_Vi_facet$`V_i`[which(ham_taz_Vi_facet$type == 'Relative Vi (exponential)')], na.rm=T) |> round()} (Vi exp), and {sum(ham_taz_Vi_facet$`V_i`[which(ham_taz_Vi_facet$type == 'Relative Vi (gamma)')], na.rm=T) |> round()} (Vi gamma)"),
              legend.is.portrait = FALSE)+
  tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
  tm_compass(position = c("left", "top"), size=1.0)+
  tm_facets("type", ncol = 3) +
  tm_layout(asp = 1.5,
            legend.outside=TRUE,
            legend.outside.position = "bottom",
            legend.position = c(0.2, 0.25),
            legend.title.size = 0.9)
```

```{r}
uncon_plots
con_plots


```



## Example from reference:

```{r}
# the example below is based on Soukhov et al. (2023) paper
travel_matrix <- data.table::data.table(
  from_id = rep(c("A", "B", "C"), each = 3),
  to_id = as.character(c("A", "B", "C"), each = 3),
  travel_time = c(15, 30, 100, 30, 15, 100, 100, 100, 15)
)
land_use_data <- data.table::data.table(
  id = c("A", "B", "C"),
  population = c(50000, 150000, 10000),
  jobs = c(100000, 100000, 10000)
)
```

```{r}
my_exp <- function(x) {
  # Do not rescale
  weights <- dexp(x, rate = 0.1)# %>% scales::rescale()
  return(weights)
}

df <- spatial_availability(
  travel_matrix,
  land_use_data,
  opportunity = "jobs",
  travel_cost = "travel_time",
  demand = "population",
  decay_function = my_exp
)
df
```

```{r}
floating_catchment_area(
  travel_matrix,
  land_use_data,
  opportunity = "jobs",
  demand = "population",
  travel_cost = "travel_time",
  decay_function = my_exp,
  method = "2sfca")
```

-   han-type accessibility (S_i)... I'm not sure, are we right or is the package? Let's check together!
-   shen-type accessibility (a_i). The package is right and we are only 2/3 right. This can be confirmed because, each i value multiplied by workers and summed should equal to the total number of opportunities. This occurs for all three imped funcs for the package but only occurs for 2 of the 3 impedance functions for our calculation (just gamma and binary). **AP: The values match for 2SFCA and for spatial availability *as long as the function is not rescaled*.**
-   spatial availability, we are right and the package is wrong? Interestingly, for the package, the results sum up to the total number of opportunities but the individual values are not equal!! **AP: This is because the allocation is still proportional but the impedance function was not the same: rescaling the function changes its shape.**

