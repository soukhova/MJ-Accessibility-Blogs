---
title: "Planning with accessibility measures II: unconstrained and constrained accessibility"
format: 
  docx: default
  html: default
editor: source
author:
  - name: Anastasia Soukhov
    email: soukhoa@mcmaster.ca
    affiliation: School of Earth, Environment and Society, McMaster University, Hamilton, ON, L8S 4K1, Canada
bibliography: bibliography.bib
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r load-packages, echo=FALSE}
library(accessibility) # Transport Accessibility Measures
library(dplyr) # A Grammar of Data Manipulation
library(ggplot2) # Create Elegant Data Visualisations Using the Grammar of Graphics
library(glue) # Interpreted String Literals
library(sf) # Simple Features for R
library(tidyr)
library(tmap) # Thematic Maps
#library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(TTS2016R) # An augmented 2016 Transportation Tomorrow Survey (TTS) data package: worker and place of employment counts, trips and estimated travel time to work in the Greater Golden Horsehoe area, Canada
```
```{r spatial-avail-function, echo=FALSE}
sp_avail_detailed <- function(x, o_id, d_id, pop, opp, r, f, alpha = 1){
  
  o_id <- rlang::enquo(o_id)
  d_id <- rlang::enquo(d_id)
  pop <- rlang::enquo(pop)
  opp <- rlang::enquo(opp)
  r <- rlang::enquo(r)
  f <- rlang::enquo(f)
  
  sum_pop <- x |>
    dplyr::distinct(!!o_id,
                    .keep_all = TRUE) |>
    dplyr::mutate(sum_pop = !!r*(!!pop)^alpha) |>
    dplyr::pull(sum_pop) |>
    sum()
  
  f_p <- dplyr::pull(x, !!r) * dplyr::pull(x, !!pop)^alpha / sum_pop
  
  # Check that the grouping here is done by the destination;
    sum_impedance <- x |>
    dplyr::group_by(!!d_id) |>
    dplyr::summarize(sum_impedance = sum(!!f))
  # Compare to lines 34-35 of function accessibility::spatial_availability() where the grouping is based on the origin:
  # data[, `:=`(impedance_bal_fac, opp_weight/sum(opp_weight)), 
  #      by = c("from_id", group_by)]
  #
  # AP: I think formula (8) and the expressions that follow in page 12 of Soukhov et al. (2023) mean that the sum is over the origins, but grouping by destinations.
  # AP: I don't necessarily think that grouping over the origins is wrong, I think it means something different...need to think more about this. The mathematical notation needs to be refined too to indicate the domain of the sums, which at the moment is somewhat ambiguous.
  
  x <- x |>
    dplyr::left_join(sum_impedance,
                     by = rlang::as_name(d_id))
  
  f_c <- dplyr::pull(x, !!f) / x$sum_impedance
  
  x$f_c <- f_c
  x$f_p <- f_p
  
  sum_pa <- x |>
    dplyr::group_by(!!d_id) |>
    dplyr::summarize(sum_pa= sum(f_p * f_c))
  
  x <- x |>
    dplyr::left_join(sum_pa,
                     by = rlang::as_name(d_id))
  x$f_t <- (f_p * f_c) / dplyr::pull(x, sum_pa)
  
  x |>
    dplyr::mutate(V_ij = !!opp * f_t)
}
```

```{r import-data}
ggh_pd <- TTS2016R::ggh_pd
ggh_pd <- st_buffer(ggh_pd, dist=0)
ggh_taz <- TTS2016R::ggh_taz
ggh_taz <- st_buffer(ggh_taz, dist=0)
ggh_taz <-  st_join(ggh_taz, ggh_pd |> transmute(PD),left = TRUE, largest = TRUE) #adding PD, we want to only visualize Hamilton PD 1

# drop travel times that have destinations
od  <- TTS2016R::od |> filter( !is.na(travel_time)) |> 
  mutate(travel_time = as.integer(ifelse(Destination == 9998 | Destination == 8888 | Origin == 9998 | Origin == 8888 
                                         | Destination >= 9000 | Origin >= 9000, NA, travel_time)))

od <- od |> 
  na.omit() #omitting rows with NA travel times - these are trips that happen to outside and/or unknown destinations.
```

```{r intra-zonal-travel-time-est-1, include=FALSE}
# Imputing intra-zonal travel time. The proposed procedure is as follows:
# 1. Calculate the inter-zonal distances using the zone centroids as reference
# 2. Calculate the square root of the area of the zones; this is a proxy for the typical distance within the zone
# 3. Model the inter-zonal travel times as a function of inter-zonal distances; This gives a relationship distance-to-time t = f(d)
# 4. Use the model to estimate (i.e., impute) the travel time

# Retrieve the centroids of the TAZ
taz_centroids <- ggh_taz |>
  st_centroid()

# Calculate the inter-centroid distances
taz_dist <- st_distance(taz_centroids,
                        taz_centroids) |>
  matrix(ncol = 1, byrow = FALSE)

# Create a data frame with the origin destination ids and the distances
taz_dist <- cbind(expand.grid(Destination = taz_centroids$GTA06, 
                              Origin = taz_centroids$GTA06),
                  taz_dist) |>
  select(Origin, Destination, taz_dist)

# Join the intra-zonal distances to the od table
od <- od |>
  left_join(taz_dist,
            by = c("Origin", "Destination"))
```

```{r intra-zonal-travel-time-est-2, echo=FALSE}
# Join area of zone
od <- od |> 
  left_join(ggh_taz |> 
              st_drop_geometry() |> 
              transmute(GTA06,
                        PD, 
                        AREA), 
            by = c("Origin" = "GTA06"))

# Calculate the square root of the area of all zones; this is a proxy of the intra-zonal distance; note that the area is in sq.km so convert to meters. The inter-zonal distances are in m.
od <- od |>
  mutate(sqrt_area = ifelse(Origin == Destination, sqrt(AREA * 1000000), NA))
```

```{r intra-zonal-travel-time-est-3, include=FALSE}
# Estimate a model to correlate distance to travel time
zonal_time_mod <- lm(travel_time ~ taz_dist,   
                     data = od |>
                       filter(Origin != Destination,
                              taz_dist < 24000))
```

```{r intra-zonal-travel-time-est-4, include=FALSE}
# Impute intrazonal travel times
od <- od |>
  mutate(travel_time = ifelse(Origin == Destination, 
                              # If intra-zonal (i.e., origin == destination) use model to impute travel time
                              zonal_time_mod$coefficients[1] + zonal_time_mod$coefficients[2] * sqrt_area,
                              # Else use the travel time already in the table
                              travel_time))
```
```{r adding-workers-and-jobs-to-land-use, include=FALSE}
workers <- od |> 
  group_by(Origin) |> 
  summarize(workers = sum(Persons))

jobs <- od |> 
  group_by(Destination) |> 
  summarize(jobs = sum(Persons))

od <- merge(od, 
            workers, 
            by="Origin")
od <- merge(od, 
            jobs, 
            by="Destination")

#update the workers and jobs in the ggh_taz file.
ggh_taz <- ggh_taz |> 
  select(-c("workers", "jobs"))
ggh_taz <- ggh_taz |> 
  merge(workers, 
        by.x = "GTA06",
        by.y="Origin",
        all = T)
ggh_taz <- ggh_taz |> 
  merge(jobs, 
        by.x = "GTA06", 
        by.y = "Destination", 
        all=T)

ggh_taz$workers |> sum(na.rm=T)
ggh_taz$jobs |> sum(na.rm=T)

#make sure that the above two lines yield the same number.. this is the number of people who make trips from origin to jobs inthe GGH (3,052,233 people)
od$Persons |> sum() 
```

```{r select-hamilton-origins, include=FALSE}
#keeping only trips originating from Hamilton IDs (the planning district of Hamilton)
ham_o_ids <- ggh_taz |> filter(PD == 46) |> data.frame() |> transmute(GTA06, AREA) #list of hamilton IDs
od_HAM_origin <- od |> filter(Origin %in% ham_o_ids$GTA06 & Destination %in% ham_o_ids$GTA06) #only keeping od trips that originate within Hamilton AND finish within Hamilton

od_HAM_origin$Persons |> sum() #104040 workers traveling from Hamilton origin IDs (and only 53270 workers originate and work within Hamilton)

ggh_taz_ham_plus <- ggh_taz |> filter(GTA06 %in% od_HAM_origin$Origin & GTA06 %in% od_HAM_origin$Destination) #updated this to be GTA06 in Hamilton (both origin AND destination)
```


```{r updating-hamilton-origins, include=FALSE}
workers <- od_HAM_origin |>
  group_by(Origin) |>
  summarize(workers = sum(Persons))

jobs <- od_HAM_origin |>
  group_by(Destination) |>
  summarize(jobs = sum(Persons))

od_HAM_origin <- od_HAM_origin %>% select(-c("workers", "jobs"))

od_HAM_origin <- merge(od_HAM_origin,
            workers,
            by="Origin")
od_HAM_origin <- merge(od_HAM_origin,
            jobs,
            by="Destination")

#update the workers and jobs in the ggh_taz file.
ggh_taz_ham_plus <- ggh_taz_ham_plus |>
  select(-c("workers", "jobs"))
ggh_taz_ham_plus <- ggh_taz_ham_plus |>
  merge(workers,
        by.x = "GTA06",
        by.y="Origin",
        all = T)
ggh_taz_ham_plus <- ggh_taz_ham_plus |>
  merge(jobs,
        by.x = "GTA06",
        by.y = "Destination",
        all=T)

ggh_taz_ham_plus$workers |> sum(na.rm=T)
ggh_taz_ham_plus$jobs |> sum(na.rm=T)

#make sure that the above two lines yield the same number.. this is the number of people who make trips from origin (Hamilton Center) to jobs anywhere in the GGH (104,040 people)
od_HAM_origin$Persons |> sum()
```

```{r creating-TLD}
#creating 1 row for each OD trip (i.e., Persons = frequency)
all_tt <- od_HAM_origin  |> dplyr::select(Persons, travel_time)
all_tt <- all_tt[rep(seq_len(dim(all_tt)[1]), all_tt$Persons), 2]
```

```{r testing-different-impedance-models, echo=FALSE, warning=FALSE, message=FALSE}
unif_ <- fitdistrplus::fitdist(data=all_tt, "unif", method="mme", optim.method="Nelder-Mead")
gamma_ <- fitdistrplus::fitdist(data=all_tt, "gamma", method="mme", optim.method="Nelder-Mead")
exp_ <- fitdistrplus::fitdist(data=all_tt, "exp", method="mme", optim.method="Nelder-Mead")
```

```{r fitting-imped-values}
travel_costs <- unique(od$travel_time)

fit_unif <- data.frame(f = dunif(travel_costs, min=0, max=unif_$estimate[2]), #already scaled from 1 to 0
                         x = travel_costs,
                         type = "Uniform")
fit_dexp <- data.frame(f = dexp(travel_costs, rate = exp_$estimate), #|> scales::rescale(),
                       x = travel_costs,
                       type = "Exp")
fit_dgamma <- data.frame(f = dgamma(travel_costs, shape = gamma_$estimate[1], rate = gamma_$estimate[2]), #|> scales::rescale(),
                         x = travel_costs,
                         type = "Gamma")

TLDs <- rbind(fit_unif, fit_dexp, fit_dgamma)
```

*This blog post is the second part of a multi-part series. This series aims to walk readers through the potential uses of accessibility measures in transportation equity planning. This post explores different accessibility measures and how the selection of the measure and the impedance function impacts outputs. See the first [post](**LINK TO POST1**) for an introduction to accessibility measures and how assumptions about travel behavior enters accessibility measures through the _impedance function_. In subsequent posts, I plan to discuss how accessibility analysis can center equity and justice conceptualizations for the purpose of planning.*

*Accessibility* (or *potential access*) has many definitions. Within the context of transportation planning, accessibility can be defined as a measure of the amount of interaction a "population" at an origin potentially has with "opportunities" at destinations in a given region. It is a product of the land-use and the population's means of transportation.

In this post, we distinguish between two types of accessibility measures: *unconstrained* and *constrained* measures. The distinction is important to help accessibility analysts interpret outputs so that they are clear on what they are measuring. 

First, let's detail **unconstrained** accessibility. The general form of the unconstrained measure, which we will from now on call $S_i$, is the measure proposed by [@hansen1959]. Many accessibility measures are derived and continue to be derived from $S_i$. $S_i$ is an accessibility value that is calculated for each spatial unit, and is appropriately termed *place-based accessibility*. This value is the summation of all the $O_j$ available (i.e., reachable) at each spatial unit according to some impedance function $f(c_{ij})$. $S_i$ is defined in @eq-hansen-access.

$$
S_i = \sum_{j=1}^JO_j \cdot f(c_{ij})
$$ {#eq-hansen-access}

\noindent Where:

-   $c_{ij}$ is a measure of the cost of moving between $i$ and $j$.
-   $f(\cdot)$ is an impedance function of $c_{ij}$; it can take the form of any monotonically decreasing function chosen based on positive or normative criteria [@paez2012measuring].
-   $i$ is a set of origin locations ($i = 1,\cdots,N$).
-   $j$ is a set of destination locations ($j = 1,\cdots,J$).
-   $O_j$ is the number of opportunities at location $j$; $O = \sum_{j=1}^J O_j$ is the total supply of opportunities in the study region.

Many variations of $S_i$ have been proposed - but largely they focus on tweaks to the type of $f(c_{ij})$ used. This measure counts $O_j$ (after being weighted by $f(c_{ij})$) for each $i$. This means that the score that is assigned to each $i$ is the summation of all the opportunities that can *potentially* be interacted with.

In lay terms, $S_i$ is a measure of the number of opportunities that someone at $i$ can potentially interact with, given their travel behaviour. However, counting all opportunities of potential interaction may not suit certain opportunities, consider the following hypothetical example.

One can live in a part of the city where they have relatively high accessibility $S_i$ to jobs as a result of land-use (e.g., close to a commercial business district) and transportation options (e.g., great roads, excellent transit). Say $S_i$ is a value of "10,000 potential job opportunities" for a neighbourhood $i$. Now, imagine if their adjacent neighbourhoods have 15,000 people who can also reach those same 10,000 job opportunities. Though they can potentially interact with a *relatively* high $S_i$ value of 10,000 opportunities, they may have less *available* opportunities as a result of relatively high neighbouring demand for opportunities. When compared to other areas of the city with relatively lower $S_i$ values but with a similar level of job opportunities and population demand, those other areas in the city may have more potential _spatial availability_ than the neighbourhood where our hypothetical person lives.

The concept described is formally known as *competition*, and has been applied to within the influential accessibility works of @shen1998 and @weibull_axiomatic_1976 as well as the widely used floating catchment areas methods (e.g., the two step floating catchment area (2SFCA) approach of @luo2003). We can think of these works as adjustments to $S_i$ (unconstrained accessibility) that account for the population's demand for opportunities in the region of interest.

In a recently published journal article, we propose an alternative derivation of accessibility by *constraining* the results to match known quantities in the system [@soukhovIntroducingSpatialAvailability2023]. These known quantities can be the total number of opportunities *or* the total population in the region under analysis. Since we constrain one of those two (opportunities or population), we think of this measure as a *singly-constrained* competitive accessibility measure ($V_i$).

In $V_i$, the total number of opportunities in the study region are preserved. So if a urban region has 100,000 opportunities, at the end of the analysis, the sum of _all_ $V_i$ values in the region is 100,000. How is this achieved? As a result of the proportional allocation feature: opportunities are allocated proportionally to each spatial units in the region based on the relative travel impedance and relative population density. We call this measure *spatial availability* which we denote as $V_i$ to distinguish it from unconstrained accessibility $S_i$. Spatial availability and its mathematical formulation is defined in @eq-spatial-avail:

$$
\begin{array}
\\V_{i} = \sum_{j=1}^NO_jF^t_{ij} \\
\text{Where: } F^t_{ij} = \frac{F^p_{i} \cdot F^c_{ij}}{\sum_{i=1}^N F^p_{i} \cdot F^c_{ij}}
\end{array}
$${#eq-spatial-avail}

\noindent where $V_i$ contains the opportunities, just as in the *unconstrained* accessibility measure $S_i$, but the allocation depends on balancing factor $F^t_{ij}$. The sum of of $F^t_{ij}$ in the region adds up to 1, which is how the sum of the spatial availability is equal to the sum of $O_j$. Revisting our hypothetical example of a urban region with 100,000 opportunities: it can be understood that both measures ($S_i$ and $V_i$) are weighted sums of opportunities, but in $S_i$ the sum of all opportunities may be more or less than the 100,000. In contrast, thanks to the proportional allocation balancing factors in $V_i$, the sum of $V_i$ values across the region is constrained to equal 100,00 opportunities.

For additional context, within $V_i$:

-   $F^t_{ij}$ is a balancing factor defined the population balancing factor ($F^p_{i} = \frac{P_{i}}{\sum_{i=1}^N P_{i}}$) and travel impedance balancing factor ($F^c_{ij} = \frac{f(c_{ij})}{\sum_{i=1}^N f(c_{ij})}$)

The balancing factor $F^p_{i}$ corresponds to the proportion of the population in origin $i$ relative to the population in the region. On the right hand side of the equation, the numerator $P_{i}$ is the population in neighbourhood $i$. The summation in the denominator is over $i=1,\cdots,N$, and adds up to the total population of the region under analysis. What does this mean practically? It means, neighbourhoods with a higher density of people get allocated more opportunities (i.e., a larger $F^p_{i}$ value), and less population dense neighborhoods get allocated smaller amounts. This measure is sensitive to demand: more people who are seeking opportunities get allocated more opportunities.  <!--Notice that we incorporate an empirical parameter $\alpha$. The role of $\alpha$ is to modulate the effect of demand by population. When $\alpha <1$, opportunities are allocated more rapidly to smaller centers relative to larger ones; $\alpha>1$ achieves the opposite effect.-->

The second balancing factor, $F^c_{ij}$ is the travel impedance (cost) balancing factor. It uses the impedance function to proportionally allocate more opportunities to neighbourhoods that are closer to (or contain) a higher density of opportunities. That is, this balancing factor assumes that populations within neighbourhoods that have lower travel impedance (less costly travel) to opportunities are *more willing* to take these opportunities as hence results in a higher value of $F^c_{ij}$ for the neighbourhood. Indeed, the travel cost balancing factor can be thought of as the proportion of the population at an 'origin' neighbourhood $i$ willing to travel to a 'destination' neighbourhood $j$, conditional on the travel behavior as described by the impedance function. What does this mean practically? It means, the higher the $F^c_{ij}$ for a neighbourhood, the more opportunities get allocated to this neighbourhood than other neighbourhoods.

Overall, $S_i$ and $V_i$ can be complex to understand - but the outputs may clarify their intuition! In what follows, we calculate and visualize the *unconstrained* and *constrained* accessibility measures discussed above. We use the best-fitting probability distribution functions as impedance functions (defined in the previous [post](**LINK TO POST1**)) to represent travel behavior in both measures $S_i$ and $V_i$.

# Differences in accessibility results

For this demonstration, **unconstrained** and **constrained** accessibility are calculated using data taken from the R data package {TTS0216R} and the home-to-work flows are provided for traffic analysis zones (TAZ). {TTS0216R} contains a subset of home-to-work flows from the 2016 Transportation Tomorrow Survey (TTS) as well as travel time by car on the road-network calculated using {r5r}. {TTS2016R} is detailed in this publication [@soukhovTTS2016RDataSet2023] and is freely available to be explored [here](https://soukhova.github.io/TTS2016R/). The focus of this demonstration is on an urban planning boundary in downtown Hamilton, Ontario (referred to in this post as Hamilton Center).

A calibrated gamma distribution probability density function serves as the impedance function for the analysis and is shown in @fig-gamma ($\alpha$ (shape) is `r gamma_$estimate[1] |> prettyNum(digits=1)` and $\sigma$ (rate) is `r gamma_$estimate[2] |> prettyNum(digits=1)`. The data set and parameters were fit using the empirical home-to-work travel data and discussed in the first blog [post](**LINK TO POST1**). But as a reminder, impedance functions represent travel behavior and the empirically observed trip length distribution. The calibrated gamma distribution best fits the sample of the empirical data used for this analysis. The values along the y-axis can be interpreted as the probability density of a trip at a certain travel time $c_{ij}$ of occurring i.e., trips of length `r fit_dgamma |> filter(f == max(f)) |> pull(x) |> prettyNum(digits=1)` minutes are the most likely to occur and hence are assigned the highest relative $f(c_{ij})$ value.

```{r plotting-impedance-functions}
#| label: fig-gamma
#| fig-cap: "The fitted theoretical gamma distribution travel impedance function of home-to-work trips (in estimated minutes by car) for Hamilton Center."

#only plotting gamma function for simplicity

ggplot(data = fit_dgamma) + geom_line(aes(x=x, y=f), size=0.6, color = "blue") + 
    scale_x_continuous(expand = c(0, 0), limits = c(0, 40)) +
  theme_classic() +
  xlab(bquote(c[ij])) +
  ylab(bquote(f(c[ij])))
```

In the following, we use the {accessibility} package to conveniently calculate unconstrained accessibility $S_i$ (@eq-hansen-access) using the gravity() function and singly-constrained accessibility $V_i$ (@eq-spatial-avail) using the spatial_availability() function. I plot the resulting scores for the Hamilton Center area for $S_i$ (Purples) and $V_i$ (Greens) in @fig-raw-con-and-unconstrained-access below:

```{r using-accessibilitypackage, include=FALSE}
#Reformatting for input into the accessibility() function. I'm doing this to test the accessibility funciton for how it calculates, unif, exp, and gamma hansen-type accessibility (S_i). 
#od_short <- od |> transmute(Origin, Destination, travel_time_coale) |>

# Retrieve jobs and workers from the same data table that was used to calculate accessibility above
# taz_short_workers <- od |>
#   transmute(id = Origin,
#             workers) |>
#   distinct(id, .keep_all = TRUE)
# 
# taz_short_jobs <- od |>
#   transmute(id = Destination,
#             jobs) |>
#   distinct(id, .keep_all = TRUE)
# 
# taz_short_2 <- taz_short_workers |>
#   full_join(taz_short_jobs,
#             by = "id") |>
#   drop_na()

# Previous version
od_short <- od_HAM_origin |> 
  transmute(Origin, 
            Destination, 
            travel_time) |>
  rename("from_id" = Origin ,
         "to_id" = Destination,
         "tt" = travel_time)

taz_short <- ggh_taz_ham_plus |> 
  st_drop_geometry() |> 
  transmute(GTA06, 
            workers, 
            jobs) |>
  rename("id" = GTA06) |> 
  mutate(workers = ifelse(is.na(workers), 0, workers),
         jobs = ifelse(is.na(jobs), 0, jobs))

my_unif <- function(x) {
  weights <- dunif(x, min=unif_$estimate[1], max=unif_$estimate[2])
  weights <- ifelse(weights == 0, 0.00000000000000000001, weights)
  return(weights)
}

my_exp <- function(x) {
  weights <- dexp(x, rate = exp_$estimate)
  # The exponential function never gives zeros
  # weights <- ifelse(weights == 0, 0.00000000000000000001, weights)
  return(weights)
}

my_gamma <- function(x) {
  weights <- dgamma(x, shape = gamma_$estimate[1], rate = gamma_$estimate[2])
  weights <- ifelse(weights == 0, 0.00000000000000000001, weights)
  return(weights)
}

# calc for package... let's try unconstrained first
unconstrained_unif <- gravity(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  travel_cost = "tt",
  decay_function = my_unif) |>   rename("S_i_unif_pkg" = jobs)

unconstrained_exp <- gravity(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  travel_cost = "tt",
  decay_function = my_exp) |>   rename("S_i_exp_pkg" = jobs)

unconstrained_gamma <- gravity(
  travel_matrix = od_short,
  land_use_data = taz_short,
  opportunity = "jobs",
  travel_cost = "tt",
  decay_function = my_gamma)  |> rename("S_i_gamma_pkg" = jobs)

package_S <- merge(unconstrained_unif,unconstrained_exp, by="id", all=T) 
package_S <- merge(package_S, unconstrained_gamma, by="id", all=T)

# add to taz 
ggh_taz <- merge(ggh_taz, package_S, by.x=("GTA06"), by.y=("id"), all=TRUE)

unconstrained_unif$S_i_unif_pkg %>% sum(na.rm=T)
unconstrained_exp$S_i_exp_pkg %>% sum(na.rm=T)
unconstrained_gamma$S_i_gamma_pkg %>% sum(na.rm=T)
```

```{r using-accessibilitypackage-2, include=FALSE}
constrained_unif <- spatial_availability(travel_matrix = od_short,
                                        land_use_data = taz_short,
                                        opportunity = "jobs",
                                        demand = "workers",
                                        travel_cost = "tt",
                                        decay_function = my_unif,
                                        alpha = 1) |> 
  rename("V_i_unif_pkg" = jobs)

constrained_exp <- spatial_availability(travel_matrix = od_short,
                                        land_use_data = taz_short,
                                        opportunity = "jobs",
                                        demand = "workers",
                                        travel_cost = "tt",
                                        decay_function = my_exp,
                                        alpha = 1) |> 
  rename("V_i_exp_pkg" = jobs)

constrained_gamma <- spatial_availability(travel_matrix = od_short,
                                        land_use_data = taz_short,
                                        opportunity = "jobs",
                                        demand = "workers",
                                        travel_cost = "tt",
                                        decay_function = my_gamma,
                                        alpha = 1) |> 
  rename("V_i_gamma_pkg" = jobs)

package_V <- merge(constrained_unif,constrained_exp, by="id", all=T) 
package_V <- merge(package_V, constrained_gamma, by="id", all=T)

# add to taz 
ggh_taz <- merge(ggh_taz, package_V, by.x=("GTA06"), by.y=("id"), all=TRUE)

constrained_unif$V_i_unif_pkg %>% sum(na.rm=T)
constrained_exp$V_i_exp_pkg %>% sum(na.rm=T)
constrained_gamma$V_i_gamma_pkg %>% sum(na.rm=T)
taz_short$jobs %>% sum() # each line should equal this number
```

```{r access-unconstrained-reformating-for-plotting}
# filter the taz so only hamilton center area. This is for plotting the results that was created using 'od_HAM_origin' and 'ggh_taz_ham_plus' 

ham_taz<- ggh_taz |> filter(PD == 46)

ham_taz <- ham_taz |> 
  mutate(S_i_unif_norm= S_i_unif_pkg / sum(S_i_unif_pkg, na.rm=T) *100,
         S_i_exp_norm= S_i_exp_pkg / sum(S_i_exp_pkg, na.rm=T)*100,
         S_i_gamma_norm = S_i_gamma_pkg / sum(S_i_gamma_pkg, na.rm=T)*100)

# add a cat. variable to each sf object and bind them with rbind. then make them into a faceted tmap. 
ham_taz_Siunif_norm <- ham_taz |>  
  mutate(type =  glue("Relative Si (uniform)") ) |>
  select(S_i_unif_norm, S_i_unif_pkg, type) |> 
  rename(Access_i_norm = S_i_unif_norm,
         Access_i = S_i_unif_pkg)

ham_taz_Siexp_norm <- ham_taz |> 
  mutate(type =  glue("Relative Si (exponential)") ) |>
  select(S_i_exp_norm, S_i_exp_pkg, type) |> 
  rename(Access_i_norm = S_i_exp_norm,
         Access_i = S_i_exp_pkg)

ham_taz_Sigamma_norm<- ham_taz|>
  mutate(type =  glue("Relative Si (gamma)") ) |>
  select(S_i_gamma_norm, S_i_gamma_pkg, type) |> 
  rename(Access_i_norm = S_i_gamma_norm,
         Access_i = S_i_gamma_pkg)

#ham_taz_Si_facet <- rbind(ham_taz_Siunif_norm, ham_taz_Siexp_norm, ham_taz_Sigamma_norm)
# ham_taz_Si_facet |> summary()
```

```{r access-constrained-reformating-for-plotting, include=FALSE}
ham_taz <- ham_taz |> 
  mutate(V_i_unif_norm= V_i_unif_pkg / sum(V_i_unif_pkg, na.rm=T) *100,
         V_i_exp_norm= V_i_exp_pkg / sum(V_i_exp_pkg, na.rm=T)*100,
         V_i_gamma_norm = V_i_gamma_pkg / sum(V_i_gamma_pkg, na.rm=T)*100)

# add a cat. variable to each sf object and bind them with rbind. then make them into a faceted tmap. 
ham_taz_Viunif_norm <- ham_taz |>  
  mutate(type =  glue("Relative Vi (uniform)") ) |>
  select(V_i_unif_norm, V_i_unif_pkg, type) |> 
  rename(Access_i_norm = V_i_unif_norm,
         Access_i = V_i_unif_pkg)

ham_taz_Viexp_norm <- ham_taz|> 
  mutate(type =  glue("Relative Vi (exponential)") ) |>
  select(V_i_exp_norm, V_i_exp_pkg, type) |> 
  rename(Access_i_norm = V_i_exp_norm,
         Access_i = V_i_exp_pkg)

ham_taz_Vigamma_norm<- ham_taz|>
  mutate(type =  glue("Relative Vi (gamma)") ) |>
  select(V_i_gamma_norm, V_i_gamma_pkg, type) |> 
  rename(Access_i_norm = V_i_gamma_norm,
         Access_i = V_i_gamma_pkg)

#ham_taz_Vi_facet <- rbind(ham_taz_Viunif_norm, ham_taz_Viexp_norm, ham_taz_Vigamma_norm)
# ham_taz_Vi_facet |> summary()

# this is interesting, around ~85,000 jobs are allocated to the Hamilton Center region. Though 102,000 jobs are located in the center and 104,000 people live there. This indicates that people who live here may not work here (?). This needs to be thought through...
ham_taz$V_i_unif_pkg |> sum(na.rm=T)
ham_taz$V_i_exp_pkg |> sum(na.rm=T)
ham_taz$V_i_gamma_pkg |> sum(na.rm=T)
#ham_taz$jobs |> sum(na.rm=T)
ham_taz$workers |> sum(na.rm=T)
ggh_taz_ham_plus$jobs|> sum(na.rm=T)
```

```{r access-con-and-unconstrained-plots}
ham_taz_facet <- cbind(ham_taz_Sigamma_norm %>% st_drop_geometry(),
                       ham_taz_Vigamma_norm) %>% st_sf()

uncon_raw_plot <- tm_shape(ham_taz_Sigamma_norm) +
  tm_polygons("Access_i",
              style = "cont",
              palette = "Purples",
              breaks = c(0, 303, 600, 828, 1692),
              label = c("0", "303 (1st Qu.)", "600 (median)","828 (3rd Qu.)", "1693 (max.)"),
              title = " ") +
  tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
  tm_compass(position = c("left", "top"), size=1.0)+
  tm_layout(legend.outside = FALSE,
            legend.position = c("left", "bottom"),
            panel.labels = expression(S[i]))

con_raw_plot <- tm_shape(ham_taz_Vigamma_norm) +
  tm_polygons(c("Access_i"),
              style = "cont",
              palette = "Greens",
              breaks = c(0, 156, 402, 671, 1954),
              label = c("0", "156 (1st Qu.)", "402 (median)", "671 (3rd Qu.)", "1954 (max.)"),
              title = " ") +
  tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
  tm_compass(position = c("left", "top"), size=1.0)+
  tm_layout(legend.outside = FALSE,
            legend.position = c("left", "bottom"),
            panel.labels = expression(V[i]))

uncon_con_raw_plot <- tmap_arrange(uncon_raw_plot, con_raw_plot, ncol = 2)
```

```{r access-con-and-unconstrained-percentage-plots}
ham_taz_facet <- rbind(ham_taz_Sigamma_norm %>% mutate(type = "Si"),
                       ham_taz_Vigamma_norm %>% mutate(type = "Vi"))

uncon_con_perc_plots <- tm_shape(ham_taz_facet) +
  tm_polygons("Access_i_norm",
              palette = c("red", "yellow", "darkgreen"),
              style ="cont",
              breaks=c(-0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, +1.8),
              label = c(">0.4%", "0.6%", "0.8%","1.0%", "1.2%","1.4%", "1.6%", "<1.8%"),
              title = glue_col("% of total potential job interactions in the region
              *out of {sum(ham_taz_Sigamma_norm$Access_i, na.rm=T) |> round()} (Si gamma), {sum(ham_taz_Vigamma_norm$Access_i, na.rm=T) |> round()} (Vi gamma)"),
              
              legend.is.portrait = FALSE)+
  tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
  tm_compass(position = c("left", "top"), size=1.0)+
  tm_facets("type", ncol = 2) +
  tm_layout(#asp = 1.5,
            legend.outside=TRUE,
            legend.outside.position = "bottom",
            legend.position = c(0.2, 0.3),
            legend.title.size = 0.9)

ham_taz_facet <- rbind(ham_taz_Sigamma_norm %>% mutate(type = "Si"),
                       ham_taz_Vigamma_norm %>% mutate(type = "Vi"))
# ham_taz_facet_diff <- ham_taz_facet |> mutate(Diff = Access_i_norm.1 - Access_i_norm)
# 
# tm_shape(ham_taz_facet_diff) +
#   tm_polygons("Diff",
#               style ="cont",
#               legend.is.portrait = FALSE)+
#   tm_scale_bar(position = c("right", "bottom"),breaks=c(0,1,2,4) )+
#   tm_compass(position = c("left", "top"), size=1.0)+
#   tm_facets("type", ncol = 2) +
#   tm_layout(#asp = 1.5,
#             legend.outside=TRUE,
#             legend.outside.position = "bottom",
#             legend.position = c(0.2, 0.3),
#             legend.title.size = 0.9)
```

```{r creating-worker-job-plot}
#NOTE: want to examine another region? Change this to PD == 1, 2, 3., etc. I think I should do this for toronto.
ggh_taz_ham_all <- (ggh_taz |> filter(PD == 46)) |> 
  st_buffer(dist=50) |>
  group_by(PD == 46) |> summarize() |>
  st_buffer(dist=150)

workers_tm <- 
  tm_shape(ggh_taz_ham_all) + tm_polygons()+
  tm_shape(ggh_taz_ham_plus |> filter(PD == 46))+
  tm_polygons(col = "workers", title = " ", style = "cont", #border.col = NULL, 
              breaks = c(17, 330, 506, 680, 1334), 
              labels = c("17 (min.)", "330 (1st Qu.)", "506 (median)", "680 (3rd Qu.)", "1334 (max.)")) +
  tm_scale_bar(breaks=c(0,1,2,4), position = c("right", "bottom") ) +
  tm_compass(position = c("right", "top"), size=1) +
  tm_layout(panel.labels = "No. of workers",
            legend.position = c("left", "bottom"))

jobs_tm <-
  tm_shape(ggh_taz_ham_all) + tm_polygons()+
  tm_shape(ggh_taz_ham_plus |> filter(PD == 46)) +
  tm_polygons(col = "jobs", title = "Jobs", style = "cont",
              palette = c("Blues"),
              breaks = c(24, 133, 263, 454, 4354), 
              labels = c("24 (min.)", "133 (1st Qu.)", "263 (median)", "453 (3rd Qu.)", "4354 (max.)")) +
  tm_scale_bar(breaks=c(0,1,2,4), position = c("right", "bottom") ) +
  tm_compass(position = c("right", "top"), size=1) +
  tm_layout(panel.labels = "No. of jobs",
            legend.position = c("left", "bottom"))

workers_jobs_plot <- tmap_arrange(workers_tm, jobs_tm, ncol = 2)
```

```{r}
#| label: fig-raw-con-and-unconstrained-access
#| fig-cap: "The calculate unconstrained (Si) and constrained (Vi) accessibility scores for Hamilton Center. Calculated using an empirically calibrated gamma distribution travel impedance function."
#| 
uncon_con_raw_plot
```

In @fig-raw-con-and-unconstrained-access, the unprocessed $S_i$ and $V_i$ scores are presented. The takeaway is the interpretation and the difference in the _magnitude_ of unconstrained ($S_i$) and constrained ($V_i$) values. Both measures reflect *potential interaction* with jobs based on empirical home-to-work travel behaviour from origins in Hamilton Center: people who reside in each spatial unit make certain trips to other spatial units and these trips have a certain travel time (travel cost $c_ij$) with associated gamma impedance $f(c_{ij}$ value. These observed trip patterns inform the calculated $S_i$ and $V_i$ values for each spatial unit.   

Looking at the left plot $S_i$ (unconstrained) in @fig-raw-con-and-unconstrained-access, the values reflect the _sum_ of jobs that can be *potentially* interacted with by the population at each $i$ multiplied by their probability of being reached as informed by the calculated travel impedance $f(c_{ij})$ value. So for Hamilton Center, the maximum $S_i$ value is the darkest purple, and that value means that people who reside in those spatial units have the _lowest_ travel impedance and _highest_ concentration of potential job interaction for the region. The value itself does not have a specific meaning as it is just the sum of 'weighted' jobs: it can be interpreted as a relative score of potential interaction based on the observed trip patterns of people who reside in Hamilton Center. For instance, areas near the west border of Hamilton Center have high (dark purple) $S_i$ values, as they are close to a major highway. So spatial units near the highway have lower travel impedance and thus can interact with more potential job opportunities. It can also be noted that there is a higher concentration of Purples within the center of the region. 

Now looking at the right plot $V_i$ (constrained) in @fig-raw-con-and-unconstrained-access, the values reflect the sum of the proportionally allocated (based on travel impedance and population) _potential job interaction_. In other words, each value of $V_i$ is the number of jobs that the spatial unit $i$ can interact with based on the observed trips made from that spatial unit's impedance values relative to how others in the region can interact with the jobs. Unlike $S_i$, the raw values of $V_i$ _do_ have a meaning in addition to being a relative score of _competitive_ potential access to jobs. This score reflects the potential _availability_ of jobs: job interactions are less likely to occur if the concentration of jobs is low and the density of people interacting with those jobs are high. So within the western region of Hamilton Center, there appears to be relatively lower intensity of $V_i$ values (Greens) than within the $S_i$ (Purples) plot, since there is a relatively higher density of population who are also interacting with jobs within this region that the $S_i$ measure does _not_ consider within its calculation.

As mentioned, the $V_i$ value in itself is also meaningful. $V_i$ values communicates the number of potentially _available_ job interactions per each spatial unit $i$ out of all the jobs in the region. If all $V_i$ values are added together, the sum equals `r ham_taz$V_i_gamma_pkg |> sum(na.rm=T) |> prettyNum(big.mark=",")` - the total number of jobs taken by people who live and work within Hamilton Center. So within the most 'Green' spatial unit, `r ham_taz_Vigamma_norm$Access_i |> max(na.rm=T) |> prettyNum(digit = 1, big.mark=",")` potentially available job interactions can occur out of the total `r ham_taz$V_i_gamma_pkg |> sum(na.rm=T) |> prettyNum(big.mark=",")` jobs based on the impedance to reach jobs and the population who also interact with these potential opportunities.

To more equally compare $S_i$ and $V_i$ and make sense of the 'highs' and 'lows', it may be useful to normalize the values onto a similar scale. In  @fig-perc-con-and-unconstrained-access, the values as presented as a percentage of the regional sum (i.e., a % of the sum of all $S_i$ values and the % of the sum of all $V_i$ values) are visualized in @fig-perc-con-and-unconstrained-access.

```{r}
#| label: fig-perc-con-and-unconstrained-access
#| fig-cap: "The calculated normalized unconstrained and constrained accessibility score for Hamilton Center. Values are presented as a percentage of the total sum of scores within the region. Values are calculated using an empirically calibrated gamma distribution travel impedance function."
uncon_con_perc_plots
```

Let's examine $S_i$ (left plot) in @fig-perc-con-and-unconstrained-access: unconstrained accessibility. Neighbourhoods with 'high' accessibility (e.g., greens, that start at 1.4% relative values or higher) can potentially interact with `r (1.4/100)*sum(ham_taz_Vigamma_norm$Access_i, na.rm=T) |> round(digits=-3)` jobs or more as informed by observed travel behaviour. These raw values are difficult to interpret, so seeing a neighbourhood as being an area of relative 'high', 'medium' (yellows) or 'low' (reds) accessibility value simplifies the interpretation of 'potential interaction' with jobs; as long as we ignore _competition_.

$V_i$ (the plot on the right side in @fig-perc-con-and-unconstrained-access) visuals singly-constrained accessibility (spatial availability). This measure does not ignore competition for potential job interaction. The general trend between both plots are similar, but you can see there are a handful of spatial units that are more intensely green or more intensely red/orange. These differences are a result of competition. Within this region, spatial units that are more densely populated as well as having below average travel impedance have higher normalized spatial availability values than $S_i$ values. Conversely, below average population and above average travel impedance yields spatial availability $V_i$ values that are lower than $S_i$. 

In essence, $V_i$ reflects travel impedance like $S_i$ does, but it also considers competition. Spatial units with orange/green $S_i$ that have red $V_i$ are a cause for concern: they likely have low travel impedance but high competition that makes their $V_i$ relatively low. Conversely, spatial units with orange/red $S_i$ that have green $V_i$ have high travel impedance but low competition for their opportunities so their spatial availability of jobs may in fact be okay! Spatial availability adds an additional layer of consideration into the accessibility measure, and as such, reveals more about the region (under the travel behaviour and opportunity accessed assumptions).

Across both $S_i$ and $V_i$ in @fig-perc-con-and-unconstrained-access, we can see some common low values (red) located in the north end of the city. From unconstrained accessibility, we know these TAZ have high relative travel impedance - this may be because people who work in the north end do not live relatively close to these opportunities so have high relative travel times. Interestingly though, we can see that there is a high relative number of jobs within these TAZ (see @fig-worker-job-plot below), however, even the number of jobs does not balance out the impedance value and higher demand for those jobs. Hence, the unconstrained accessibility measure is also low.

```{r worker-job-plot}
#| label: fig-worker-job-plot
#| fig-cap: "The number of workers and jobs in Hamilton Center. Note: only workers who reside and work within Hamilton Center are considered in the accessibility calculations for this demonstration."
workers_jobs_plot
```


## Concluding remarks
To summarize, potential interaction with job opportunities is presented in the plots only for the population in Hamilton Center than both lives and works within Hamilton Center. Unconstrained accessibility only considers the jobs that can be potentially interacted with by the population based on travel impedance. Constrained accessibility considers travel impedance in addition to the demand for jobs (i.e., the population). 

Accessibility is a unique measure that characterizes the relationship between land-use (where populations reside and the opportunities they can interact with) in addition to transportation travel impedance. How the relationship is conceptualization (i.e., if there's competition or not) and how the travel impedance is calibrated (i.e., what function describes travel behaviour) are critical in determining what the final values are and how to interpret them.

The constrained accessibility measure we demonstrate is spatial availability $V_i$, which has a proportional allocation feature. Since the number of opportunities for the region is proportionally allocated to each origin - the raw output can be used to plan for how many more opportunities are needed for each origin. Furthermore, though not demonstrated in this post, spatial availability values can also be divided by population at that origin. This can be interpreted as an opportunity per capita value. This value can be used as a benchmark to compare again opportunity per capita across areas of the region and between regions. This, along with different equity conceptualizations, will be explored in a future post. 

Considering competition is important for certain opportunity types and using the spatial availability method allows for the resulting unprocessed value to be interpretable. For instance, places of employment are a _non-divisible_ type of opportunity, they only allow one person to take one job. Unless there's a reason to _not_ consider competition, measuring access to jobs using an unconstrained measure $S_i$ does not make much theoretical sense from an opportunity-planning perspective. Spatial availability is also valuable if interested in levels of service (opportunities per capita) levels.

On the flipside, if opportunities are divisible (i.e., capacity of the opportunity doesn't matter or the demand for the opportunity doesn't matter much either) than unconstrained $S_i$ makes more theoretical sense. Ultimately, unconstrained accessibility $S_i$ tells you how many opportunities can be potentially reached. Spatial availability tells you how many opportunities are _available_ based on how many can be potentially reached and demanded. Consider it as a measure of potential opportunity access that you can reach and that has not been 'taken' up yet.

Depending on how the accessibility analysis is conducted sheds light on regions of inequitable potential access. Assumptions on what region to analyse, what population and opportunities are the subject of analysis, the travel cost unit and calculation, the impedance function and the measure used all impact the final results. But ultimately, the output represents the number of opportunities that could *potentially* be reached from each origin. It is critical that the assumptions embedded within each step of analysis are understood so that the final value can be interpreted and inequities can be identified.

Once these spatial inequities have been identified - what do we do about it? That is the subject for a future post.

Openness is legitimacy: this blog post was written in a R environment and can be fully reproduced from the materials available at this GitHub ([repository](https://github.com/soukhova/MJ-Accessibility-Blogs)). If interested, see the open access PDF of the full article (which includes the mathematical formulation for the spatial availability function) in the references [@soukhovIntroducingSpatialAvailability2023]. 

_The data used in this post is a subset of data from {TTS2016R}, the plots are created using {tmap}, and spatial objects are manipulated using {sf}, along with base {R} functions._

```{r comparing-to-manual-calc1, eval=FALSE}
#let's check to see if the calculated S_i and V_i is equal to manual calculation...

#first S_i -- it's the same!
LOS_j <- od_HAM_origin |>
  mutate(f_unif = dunif(travel_time, min=unif_$estimate[1], max=unif_$estimate[2]),
         f_unif = ifelse(f_unif == 0, 0.00000000000000000001, f_unif),
         f_exp = dexp(travel_time, rate = exp_$estimate),
         f_gamma = dgamma(travel_time, shape = gamma_$estimate[1], rate = gamma_$estimate[2]),
         f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) |>
  group_by(Destination) |>
  summarize(opp = first(jobs),
            R_j_unif = sum(workers * f_unif),
            R_j_exp = sum(workers * f_exp),
            R_j_gamma = sum(workers * f_gamma),
            .groups = "drop") |>
  mutate(R_j_unif = ifelse(R_j_unif == 0, NA, R_j_unif),
         #R_j_exp = ifelse(R_j_exp == 0,0.00000000000000000001, R_j_exp),
         #R_j_gamma = ifelse(R_j_gamma == 0,0.00000000000000000001, R_j_gamma),
         LOS_j_unif = opp/R_j_unif,
         LOS_j_exp = opp/R_j_exp,
         LOS_j_gamma = opp/R_j_gamma)

# Hansen- accessibility
S <- od_HAM_origin |>
  mutate(f_unif = dunif(travel_time, min=unif_$estimate[1], max=unif_$estimate[2]),
         f_unif = ifelse(f_unif == 0, 0.00000000000000000001, f_unif),
         f_exp = dexp(travel_time, rate = exp_$estimate),
         f_gamma = dgamma(travel_time, shape = gamma_$estimate[1], rate = gamma_$estimate[2]),
         f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) |>
  left_join(LOS_j |> 
              dplyr::select(Destination),
            by = "Destination") |>
  group_by(Origin) |>
  summarize(S_i_unif= sum(jobs * f_unif, na.rm=T),
            S_i_exp= sum(jobs * f_exp, na.rm=T), 
            S_i_gamma = sum(jobs * f_gamma, na.rm=T))

# compare calculated to the packaged calculated S
comp_S <- merge(package_S, S, by.x="id", by.y ="Origin", all=T) 

data.frame(comp_S$S_i_unif_pkg, comp_S$S_i_unif,
           comp_S$S_i_exp_pkg, comp_S$S_i_exp,
           comp_S$S_i_gamma_pkg, comp_S$S_i_gamma)
```

```{r comparing-to-manual-calc-test2, eval=FALSE}
#now V_i
# Spatial availability disaggregated - binary
V_ij_unif <- od_HAM_origin |>
  mutate(f_unif = dunif(travel_time, min=unif_$estimate[1], max=unif_$estimate[2]),
         f_unif = ifelse(f_unif == 0, 0.00000000000000000001, f_unif),
         f_exp = dexp(travel_time, rate = exp_$estimate),
         f_gamma = dgamma(travel_time, shape = gamma_$estimate[1], rate = gamma_$estimate[2]),
         f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) |>
  #mutate(f_bin = ifelse(f_bin == 0, 0.00000000000000000001, f_bin)) |>
  mutate(r = 1) |>
  sp_avail_detailed(o_id = Origin,
                    d_id = Destination, 
                    pop = workers, 
                    opp = jobs, 
                    r = r, 
                    f = f_unif, 
                    alpha = 1.0) #alpha 1.54 

V_i_unif <- V_ij_unif |>
  group_by(Origin) |>
  summarise(V_i_unif = sum(V_ij))

# Spatial availability disaggregated - exponential
V_ij_exp <- od_HAM_origin |>
  mutate(f_unif = dunif(travel_time, min=unif_$estimate[1], max=unif_$estimate[2]),
         f_unif = ifelse(f_unif == 0, 0.00000000000000000001, f_unif),
         f_exp = dexp(travel_time, rate = exp_$estimate),
         f_gamma = dgamma(travel_time, shape = gamma_$estimate[1], rate = gamma_$estimate[2]),
         f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) |>
  mutate(r = 1) |>
  sp_avail_detailed(o_id = Origin,
                    d_id = Destination, 
                    pop = workers, 
                    opp = jobs, 
                    r = r, 
                    f = f_exp, 
                    alpha = 1.0) #alpha 1.54 

V_i_exp <- V_ij_exp |>
  group_by(Origin) |>
  summarise(V_i_exp = sum(V_ij)) |> 
  select(-Origin)

# Spatial availability disaggregated - gamma
V_ij_gamma <- od_HAM_origin |>
  mutate(f_unif = dunif(travel_time, min=unif_$estimate[1], max=unif_$estimate[2]),
         f_unif = ifelse(f_unif == 0, 0.00000000000000000001, f_unif),
         f_exp = dexp(travel_time, rate = exp_$estimate),
         f_gamma = dgamma(travel_time, shape = gamma_$estimate[1], rate = gamma_$estimate[2]),
         f_gamma = ifelse(f_gamma == 0, 0.00000000000000000001, f_gamma)) |>
  mutate(r = 1) |>
  sp_avail_detailed(o_id = Origin,
                    d_id = Destination, 
                    pop = workers, 
                    opp = jobs, 
                    r = r, 
                    f = f_gamma, 
                    alpha = 1.0) #alpha 1.54 

V_i_gamma <- V_ij_gamma |>
  group_by(Origin) |>
  summarise(V_i_gamma = sum(V_ij)) |>
  select(-Origin)

V <- cbind(V_i_unif, V_i_exp, V_i_gamma)

# compare calculated to the packaged calculated S
comp_V <- merge(package_V, V, by.x="id", by.y ="Origin", all=T) 

data.frame(comp_V$V_i_unif_pkg, comp_V$V_i_unif,
           comp_V$V_i_exp_pkg, comp_V$V_i_exp,
           comp_V$V_i_gamma_pkg, comp_V$V_i_gamma)

```

## References





<!-- Interestingly though, the trends within the $S_i$ plots (different impedance functions) row visually look similar: TAZ that have 'high', 'medium' and 'low' values are similar across all plots. This indicates that the selection of impedance function, at least within this visualization, does not result in too much variation in the results. As discussed in the first [post](**LINK TO BLOG POST1**), the selection of parameters for all impedance functions were optimally derived from empirical home-to-work travel flows, so seeing similar trends across plots is not unexpected. The selection of the parameters may matter more than the shape (i.e., type of theoretical distribution selected). -->